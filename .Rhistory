exp(0.064)
exp(0.0064)
meanFemales <- mean(dataSet[dataSet$Sex=="F",]$LogRT)
meanMales <- mean(dataSet[dataSet$Sex=="M",]$LogRT)
meanFemales
meanMales
SE
SE <- sd(dataSet$LogRT)/sqrt(nrow(dataSet))
SE
confMeanFemales <- c(meanFemales-(1.96*SE), meanFemales+(1.96*SE))
confMeanFemales
difference <- meanFemales -meanMales
confDifference <- c(difference-(1.96*SE), difference+(1.96*SE))
confDifference
effectSize<-(meanFemales -meanMales)/sd(dataSet$LogRT)
effectSize
effectSize<-(meanFemales -meanMales)/sd(dataSet$LogRT)
effectDifference <- c(effectSize-(1.96*SE), effectSize+(1.96*SE))
effectDifference
shapiro.test(dataSet$LogRT)
colnames(dataSet)
dataSet <- read_csv("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
dataSet <- dataSet[dataSet$pos %in% c("noun", "adjective"),]
nrow(dataSet)
write_csv(dataSet, "/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
summary(dataSet)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
summary(dataSet$word_length)
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density")
ggplot(dataSet, aes(x=word_length)) + geom_line(stat="density")
ggplot(dataSet, aes(x=word_length)) + geom_line(stat="density") + geom_vline(aes(xintercept=mean(dataSet$word_length), color="red"))
wilcox.test(word_length ~ pos, data = dataSet, correct = FALSE, conf.int = TRUE)
median(dataSet[dataSet$pos=="noun",]$word_length) -  median(dataSet[dataSet$pos=="adjective",]$word_length)
median(dataSet[dataSet$pos=="noun",]$word_length)
edian(dataSet[dataSet$pos=="adjective",]$word_length)
median(dataSet[dataSet$pos=="adjective",]$word_length)
?wilcox.test
dataSet$pos <- as.factor(dataSet$pos)
dataSet$pos <- relevel(dataSet$pos, ref="noun")
wilcox.test(word_length ~ pos, data = dataSet, alternative="less")
?c`c orrect``
dataSet$pos <- as.factor(dataSet$pos)
dataSet$pos <- relevel(dataSet$pos, ref="noun")
wilcox.test(word_length ~ pos, data = dataSet, alternative="less", conf.int=TRUE)
mean(dataSet[dataSet$pos=="noun",]$word_length) -  mean(dataSet[dataSet$pos=="adjective",]$word_length)
dataSet$pos <- as.factor(dataSet$pos)
dataSet$pos <- relevel(dataSet$pos, ref="noun")
wilcox.test(word_length ~ pos, data = dataSet, alternative="less", conf.int=TRUE, exact=T)
931790/sqrt(nrow(dataSet))
median(dataSet[dataSet$pos=="noun",]$word_length) -  median(dataSet[dataSet$pos=="adjective",]$word_length)
median(dataSet[dataSet$pos=="noun",]$word_length) -  median(dataSet[dataSet$pos=="adjective",]$word_length)
SE<-sd(dataSet$word_length)/sqrt(nrow(dataSet)
)
SE
SE<-sd(dataSet$word_length)/sqrt(nrow(dataSet))
confintDiff<-c(difference -  (1.96*SE), difference +  (1.96*SE))
confintDiff
difference <- median(dataSet[dataSet$pos=="noun",]$word_length) -  median(dataSet[dataSet$pos=="adjective",]$word_length)
difference
difference -  (1.96*SE)
confintDiff<-c(difference -(1.96*SE), difference +  (1.96*SE))
confintDiff
difference <- median(dataSet[dataSet$pos=="noun",]$word_length) -  median(dataSet[dataSet$pos=="adjective",]$word_length)
difference
SE<-sd(dataSet$word_length)/sqrt(nrow(dataSet))
confintDiff<-c(difference -(1.96*SE), difference +(1.96*SE))
confintDiff
head(dataSet)
library(readr)
dataSet<-read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Balling_Baayen_2008.csv")
summary(dataSet$LogRT)
head(dataSet)
SE <- sd(dataSet$LogRT)/sqrt(nrow(dataSet))
SE
ggplot(dataSet, aes(x=Sex)) + stat_summary(fun.y = mean, geom="bar") + stat_summary(fun.ymax = mean_se, geom="errorbar")
ggplot(dataSet, aes(x=Sex)) + stat_summary(fun.y = mean, geom="bar", stat="identity") + stat_summary(fun.ymax = mean_se, geom="errorbar")
dataForPLot
dataForPLot <- dataSet %>%
group_by(Sex) %>%
summarise( lowerBound=mean(LogRT)-(1.96*sqrt(nrow(dataSet))), upperBound=mean(LogRT)+(1.96*sqrt(nrow(dataSet))),  mean=mean(LogRT))
dataForPLot
mean(LogRT)-(1.96*sqrt(nrow(dataSet)
)
)
SE <- sd(dataSet$LogRT) /sqrt(nrow(dataSet))
SE
SE <- sd(dataSet$LogRT) /sqrt(nrow(dataSet))
dataForPLot <- dataSet %>%
group_by(Sex) %>%
summarise( lowerBound=mean(LogRT) - (1.96*SE),
upperBound=mean(LogRT)+(1.96*SE),
mean=mean(LogRT))
dataForPLot
ggplot(dataForPLot, aes(x=Sex, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), color="gray", width=0.5)
ggplot(dataForPLot, aes(x=Sex, y=mean, color=Sex, fill=Sex)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), color="gray", width=0.5)
ggplot(dataForPLot, aes(x=Sex, y=mean, color=Sex, fill=Sex)) + geom_bar(stat="identity") + geom_errorbar(aes(y.min=lowerBound, y.max=upperBound), color="gray", width=0.5)
ggplot(dataForPLot, aes(x=Sex, y=mean, color=Sex, fill=Sex)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), color="grey", width=0.5)
confMedian <- function(x) {
j <- round(length(x)/2 - (1.96*sqrt(length(x)/4)))
k <-round(length(x)/2 +(1.96*sqrt(length(x)/4)))
c(sort(x)[j], sort(x[k]))
}
dataForPLot <- dataSet %>%
group_by(Sex) %>%
summarise( lowerBound=confMedian(LogRT),
upperBound=confMedian(LogRT),
mean=mean(LogRT))
dataForPLot
dataForPLot <- dataSet %>%
group_by(Sex) %>%
summarise( lowerBound=confMedian(LogRT[1]),
upperBound=confMedian(LogRT)[2],
mean=mean(LogRT))
dataForPLot
dataForPLot <- dataSet2 %>%
group_by(pos) %>%
summarise( lowerBound=confMedian(word_length)[1],
upperBound=confMedian(word_length)[2],
mean=median(word_length))
dataForPLot
dataSet2 <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
summary(dataSet$word_length)
dataSet2 <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
summary(dataSet2$word_length)
confMedian <- function(x) {
j <- round(length(x)/2 - (1.96*sqrt(length(x)/4)))
k <-round(length(x)/2 +(1.96*sqrt(length(x)/4)))
c(sort(x)[j], sort(x[k]))
}
dataForPLot <- dataSet2 %>%
group_by(pos) %>%
summarise( lowerBound=confMedian(word_length)[1],
upperBound=confMedian(word_length)[2],
mean=median(word_length))
dataForPLot
confMedian <- function(x) {
j <- round(length(x)/2 - (1.96*sqrt(length(x)/4)))
k <-round(length(x)/2 +(1.96*sqrt(length(x)/4)))
c(sort(x)[j], sort(x[k]))
}
dataForPLot <- dataSet2 %>%
group_by(pos) %>%
summarise( lowerBound=confMedian(word_length)[1],
upperBound=confMedian(word_length)[2],
median=median(word_length))
dataForPLot
ggplot(dataForPLot, aes(x=pos, y=median, color=pos, fill=pos)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), color="grey", width=0.5)
ggplot(dataForPLot, aes(x=Sex, y=mean, color=Sex, fill=Sex)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), color="grey", width=0.5)
SE <- sd(dataSet$LogRT) /sqrt(nrow(dataSet))
dataForPLot <- dataSet %>%
group_by(Sex) %>%
summarise( lowerBound=mean(LogRT) - (1.96*SE),
upperBound=mean(LogRT)+(1.96*SE),
mean=mean(LogRT))
dataForPLot
ggplot(dataForPLot, aes(x=Sex, y=mean, color=Sex, fill=Sex)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), color="grey", width=0.5)
citation("languageR")
citation("languageR")
library(languageR)
confMedian <- function(x) {
lower <- round(length(x)/2 - (1.96*sqrt(length(x)/4)))
upper <-round(length(x)/2 +(1.96*sqrt(length(x)/4)))
c(sort(x)[lower], sort(x[upper]))
}
confMedian(dataSet2$word_length)
median(dataSet2$word_length)
library(Rling)
load("/Users/jeroenclaes/Downloads/Rling 2/data/ELP.RData")
head(ELP)
shapiro.test(ELP$Mean_RT)
shapiro.test(ELP$SUBTLWF)
shapiro.test(ELP$Length)
nrow(ELP)
load("/Users/jeroenclaes/Downloads/Rling 2/data/time_training.RData")
head(time_training)
shapiro.test(time_training$rt)
nrow(time_training)
unique(time_training$Lang)
unique(time_training$Prime)
unique(time_training$Subj)
install.packages("/Users/jeroenclaes/Downloads/Rling_1.0.tar.gz")
install.packages("/Users/jeroenclaes/Downloads/Rling_1.0.tar.gz", repos=NULL, source=T)
library(Rling)
?Rling
?Rling::ELP
View(Rling::ELP)
??Rling
?`Rling-package`
load("/Users/jeroenclaes/Downloads/Rling 2/data/pym_high.RData")
load("/Users/jeroenclaes/Downloads/Rling 2/data/pym_low.RData")
glimpse(pym_high)
glimpse(pym_low)
pym_low$type <- "low"
pym_high$type <- "high"
pym <- rbind(pym_high, pym_low)
View(pym)
pym$word <- row.names(pym)
colnames(pym) <- c("syllables", "characters", "concreteness", "associations", "type", "word")
?pym_high
write_csv(pym, "../datasets/class4_paivio_et_al_1968.csv")
shapiro.test(pym$syllables)
shapiro.test(pym$characters)
shapiro.test(pym$concreteness)
shapiro.test(pym$associations)
shapiro.test(pym$type)
colnames(pym_low)
colnames(pym) <- c("syllables", "characters", "imagery", "concreteness", "associations", "type", "word")
write_csv(pym, "../datasets/class4_paivio_et_al_1968.csv")
shapiro.test(pym$associations)
install.packages("haven")
library(haven)
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/Eddington & Ruiz de Mendoza.sav")
head(exc)
View(exc)
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/Eddington&Savage2012.sav")
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/LafranceGottardo.sav")
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/LarsonHall2008.sav")
mean(exc$useeng, na.rm = T)
median(exc$useeng, na.rm = T)
median(exc$convlev, na.rm = T)
mean(exc$convlev, na.rm = T)
qqnorm(exc$convlev)
qqline(exc$convlev)
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/LarsonHallPartial.sav)
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/LarsonHallPartial.sav")
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/surfer_F2.sav")
exc$Surfer_or_nonSurfer<-ifelse(exc$Surfer_or_nonSurfer==0, "Non-surfer", "surfer")
nrow(exc)
table(exc$Surfer_or_nonSurfer)
head(exc)
write_csv(exc, "../datasets/class4_dude.csv")
ggplot(dataSet, aes(x=Surfer_or_nonSurfer, y=F2)) + geom_boxplot()
dataSet<-exc
ggplot(dataSet, aes(x=Surfer_or_nonSurfer, y=F2)) + geom_boxplot()
tData<-read_csv("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/class4_paivio_et_al_1968.csv")
summary(tData)
shapiro.test(tData$associations)
unique(tData$type)
head(tData$word)
dataSet <- tData
ggplot(dataSet, aes(x=associations)) + geom_line(stat="density")
ggplot(dataSet, aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept=mean(dataSet$associations)), color="red")
# The data.frame dataSet is already in your workspace
# We should test the assumptions of the t-test first
# Count the number of rows in the data.frame. Is the sample size > 30?
nrow(dataSet)
# Is the 'associations' variable normally distributed? Draw up a density plot
# Add a red vertical line at the mean
library(ggplot2)
ggplot(dataSet, aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept=mean(dataSet$associations)), color="red")
# Draw a qqplot with a qqline
qqnorm(dataSet$associations)
qqline(dataSet$associations)
# Perform a shapiro-wilk test
shapiro.test(dataSet$associations)
# Is the variable normally distributed? You will find the correct answer on the Solution tab
# Yes, the variable approaches the normal distribution:
# - The distribution shows up as a bell-shaped curve in the density plot (but, there is a slight negative skew)
#  - The dots follow the QQ-line
# - p > 0.05 in the Shapiro-Wilk test
qqnorm(dataSet$associations)
qqline(dataSet$associations)
ggplot(dataSet, aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept=mean(dataSet$associations)), color="red")
library(testwhat)
exc<-read_sav("/Users/jeroenclaes/Desktop/statistics_for_linguistics/datasets/eddington/Eddington & Ruiz de Mendoza.sav")
head(exc)
exc <- exc[,c(1,2, 3)]
exc
exc<-exc[!is.na(exc$TestSentence),]
nrow(exc    )
library(tidyr   )
?gather
ex2 <- exc %>% gather(key=TestSentence, value="Mean_RT")
ex2 <- exc %>% gather(key="condition", value="Mean_RT")
head(ex2)
ex2 <- exc %>% gather(key="condition", value="Mean_RT", -TestSentence)
ex2
ex2$TestSentence <- paste("Sentence ", ex2$TestSentence)
ex2
ex2$condition <- recode(ex2$condition, "MeanRT_syntax"="only syntax", "MeanRT_syntax_and_semantics"="syntax and semantics")
ex1
ex2
ex2 <- ex2 %>% group_by(TestSentence, condition) %>% mutate(difference=Mean_RT[which(condition=="only syntax")]-Mean_RT[which(condition=="syntax and semantics")])
ex2 <- ex2 %>% group_by(TestSentence, condition) %>% mutate(difference=Mean_RT[1]-Mean_RT[2])
ex2
ex2 <- ex2 %>% group_by(TestSentence) %>% mutate(difference=Mean_RT[1]-Mean_RT[2])
ex2
shapiro.test(ex2$difference)
ex2 <- ex2 %>% group_by(TestSentence) %>% mutate(difference=Mean_RT[which(condition=="only syntax")]-Mean_RT[which(condition=="syntax and semantics")])
ex2
shapiro.test(ex2$difference)
ex2 <- ex2 %>% group_by(TestSentence) %>% mutate(difference=Mean_RT[which(condition=="syntax and semantics")]-Mean_RT[which(condition=="only syntax")])
shapiro.test(ex2$difference)
ggplot(ex2, aes(x=difference)) + geom_line(stat="density")
ggplot(ex2, aes(x=Mean_RT)) + geom_line(stat="density")
ggplot(ex2, aes(x=unique(difference))) + geom_line(stat="density")
ggplot(ex2[!duplicated(ex2$difference),], aes(x=Mean_RT)) + geom_line(stat="density")
shapiro.test(duplicated(ex2$difference),]$difference)
shapiro.test(ex2[!duplicated(ex2$difference),]$difference)
ex2 <- ex2 %>% select(-difference)
write_csv(ex2, "class4_Eddington_and_Ruiz-Mendoza_2008.csv")
write_csv(ex2, "class4_Eddington_and_Ruiz-Mendoza_2010.csv")
t.test(Mean_RT ~ condition, data = exc2, paired=TRUE)
t.test(Mean_RT ~ condition, data = ex2, paired=TRUE)
t.test(Mean_RT ~ condition, data = ex2, paired=TRUE, alternative="less")
t.test(Mean_RT ~ condition, data = ex2, paired=TRUE, alternative="greater")
differences <- ex2[ex2$condition=="only syntax", ]$Mean_RT - ex2[ex2$condition=="syntax and semantics", ]$Mean_RT
differences
qqnorm(differences)
qqline(differences)
sort(differences)
exc
exc$diff<-exc$MeanRT_syntax-exc$MeanRT_syntax_and_semantics
View(exc)
ex2
differences <- ex2[which(ex2$condition=="only syntax" & ! ex2$TestSentence %in% c("Sentence 4", "Sentence 8")), ]$Mean_RT - ex2[which(ex2$condition=="syntax and semantics"& ! ex2$TestSentence %in% c("Sentence 4", "Sentence 8")), ]$Mean_RT
differences
qqnorm(differences)
qqline(differences)
differences <- ex2[which((ex2$condition=="only syntax") & (!ex2$TestSentence %in% c("Sentence 4", "Sentence 8"))), ]$Mean_RT - ex2[which((ex2$condition=="syntax and semantics") & (!ex2$TestSentence %in% c("Sentence 4", "Sentence 8"))), ]$Mean_RT
length(difference)
difference
differences
differences <- ex2[which((ex2$condition=="only syntax") && (!ex2$TestSentence %in% c("Sentence 4", "Sentence 8"))), ]$Mean_RT - ex2[which((ex2$condition=="syntax and semantics") && (!ex2$TestSentence %in% c("Sentence 4", "Sentence 8"))), ]$Mean_RT
differences
shapiro.test(differences)
shapiro.test(exc$diff)
shapiro.test(ex2$Mean_RT)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_dude.csv")
shapiro.test(dataSet$F2)
ggplot(dataSet, aes(x=F2)) + geom_line(stat="density")
qqnorm(dataSet$F2)
qqline(dataSet$F2)
library(readr)
dataSet<-read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Perdijk_et_al_2006.csv")
summary(dataSet$LogRT)
shapiro.test(dataSet[dataSet$Word=="ui",]$LogRT)
qqnorm(dataSet$LogRT)
qqline(dataSet$LogRT)
shapiro.test(dataSet[dataSet$Word=="ui",]$LogRT)
shapiro.test(dataSet[dataSet$Word=="grinniken",]$LogRT)
par(mfcol=2)
par()
par(mfcol=2, mfrow=1)
par(mfcol=c(1, 2), mfrow=1)
dataSet2 <- dataSet %>%
group_by(Subject) %>%
filter(n() >1) %>%
mutate(diff=LogRT[which(Word=="grinniken")]-LogRT[which(Word=="ui")]) %>%
ungroup()
pandoc.table(head(dataSet2, 10))
dataSet2 <- dataSet %>%
group_by(Subject) %>%
filter(n() >1) %>%
mutate(diff=LogRT[which(Word=="grinniken")]-LogRT[which(Word=="ui")]) %>%
ungroup() %>%
arrange(Subject)
pandoc.table(head(dataSet2, 10))
shapiro.test(dataSet2[!duplicated(dataSet2$diff), ]
shapiro.test(dataSet2[!duplicated(dataSet2$diff), ])
shapiro.test(dataSet2[!duplicated(dataSet2$diff), ]$diff)
qqnorm(dataSet2[!duplicated(dataSet2$diff), ]$diff)
qqline(dataSet2[!duplicated(dataSet2$diff), ]$diff)
t.test(LogRT ~ Word, data=dataSet2, alternative="two.sided")
dataSet2$Word <- as.factor(dataSet2$Word)
dataSet2$Word <- relevel(dataSet2$Word, ref="ui")
t.test(LogRT ~ Word, data=dataSet2, alternative="two.sided")
d <- (mean(dataSet[dataSet$Word=="ui",]$LogRT) - mean(dataSet[dataSet$Word=="grinniken",]$LogRT))/
sd(dataSet$LogRT)
d
dataSet2 <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Davies_2008_coca_frequency.csv")
summary(dataSet2$coca_frequency)
ggplot(dataSet2[dataSet2$pos=="noun"], aes(x=coca_frequency)) +
geom_line(stat="density") +
geom_vline(aes(xintercept=mean(dataSet2$coca_frequency)), color="red")
ggplot(dataSet2[dataSet2$pos=="noun",], aes(x=coca_frequency)) +
geom_line(stat="density") +
geom_vline(aes(xintercept=mean(dataSet2$coca_frequency)), color="red")
ggplot(dataSet2[dataSet2$pos=="adjective",], aes(x=coca_frequency)) +
geom_line(stat="density") +
geom_vline(aes(xintercept=mean(dataSet2$coca_frequency)), color="red") + labs(title="Adjectives")
unique(dataSet2$pos)
ggplot(dataSet2[dataSet2$pos=="adjective",], aes(x=coca_frequency)) +
geom_line(stat="density") +
geom_vline(aes(xintercept=mean(dataSet2$coca_frequency)), color="red") + labs(title="Adjectives")
ggplot(dataSet2[dataSet2$pos=="noun",], aes(x=coca_frequency)) +
geom_line(stat="density") +
geom_vline(aes(xintercept=mean(dataSet2$coca_frequency)), color="red") + labs(title="Nouns")
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_dude.csv")
ggplot(dataSet[dataSet$Surfer_or_nonSurfer=="surfer", ], aes(x=F2)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$Surfer_or_nonSurfer=="surfer", ]$F2) ), color="red")
head(dataSet)
ggplot(dataSet[dataSet$Surfer_or_nonSurfer=="Non-surfer", ], aes(x=F2)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$Surfer_or_nonSurfer=="Non-surfer", ]$F2) ), color="red")
shapiro.test(dataSet[dataSet$Surfer_or_nonSurfer=="surfer", ]$F2)
shapiro.test(dataSet[dataSet$Surfer_or_nonSurfer=="Non-surfer", ]$F2)
t.test(F2 ~ Surfer_or_nonSurfer, data=dataSet, alternative="less")
dataSet$Surfer_or_nonSurfer <- as.factor(dataSet$Surfer_or_nonSurfer)
dataSet$Surfer_or_nonSurfer <- relevel(dataSet$Surfer_or_nonSurfer, ref="surfer")
t.test(F2 ~ Surfer_or_nonSurfer, data=dataSet, alternative="less")
t.test(F2 ~ Surfer_or_nonSurfer, data=dataSet, alternative="greater")
(mean(dataSet[dataSet$Surfer_or_nonSurfer=="surfer",]$F2) - mean(dataSet[dataSet$Surfer_or_nonSurfer=="Non-surfer",]$F2))/sd(dataSet$F2)
sd(dataSet$F2)
(mean(dataSet[dataSet$Surfer_or_nonSurfer=="surfer",]$F2)
)
(mean(dataSet[dataSet$Surfer_or_nonSurfer=="Non-surfer",]$F2))
1811.726-1702.617
109.109/74.49889
# The data.frame dataSet is already in your workspace
# Convert 'Surfer_or_nonSurfer' to a factor
# Relevel 'Surfer_or_nonSurfer' so that the reference level is 'surfer'
# Calculate the standard error of the F2 variable (standard deviation/square root of sample size)
# Load the 'dplyr' package
# Calculate the data for the plot:
dataForPlot <- dataSet %>%
group_by(_) %>%
SE<-sd(dataSet$F2)/sqrt(nrow(dataSet))
SE
dataForPlot <- dataSet %>%
group_by(Surfer_or_nonSurfer) %>%
summarise(lowerBound= mean(F2)-(1.96*SE),
upperBound=mean(F2)+(1.96*SE),
mean=mean(F2))
ggplot(dataForPlot, aes(x=Surfer_or_nonSurfer, y=mean, color=Surfer_or_nonSurfer, fill=Surfer_or_nonSurfer)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5)
v
ggplot(dataForPlot, aes(x=Surfer_or_nonSurfer, y=mean, color=Surfer_or_nonSurfer, fill=Surfer_or_nonSurfer)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5, color="grey")
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Paivio_et_al_1968.csv")
ggplot(dataSet, aes(x=type, y=F2)) + geom_boxplot()
ggplot(dataSet, aes(x=type, y=associations)) + geom_boxplot()
ggplot(dataSet[dataSet$type=="high", ], aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$type=="high", ]$associations) ), color="red")
ggplot(dataSet[dataSet$type=="low", ], aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$type=="low", ]$associations) ), color="red")
shapiro.test(dataSet[dataSet$type=="high", ]$associations)
shapiro.test(dataSet[dataSet$type=="low", ]$associations)
ggplot(dataSet[dataSet$type=="low", ], aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$type=="low", ]$associations) ), color="red")
ggplot(dataSet[dataSet$type=="high", ], aes(x=associations)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$type=="high", ]$associations) ), color="red")
nrow()
nrow(dataSet[dataSet$type=="high", ])
nrow(ataSet[dataSet$type=="low", ])
nrow(dataSet[dataSet$type=="low", ])
dataSet$type <- as.factor(dataSet$type)
v
dataSet$type <- relevel(dataSet$type, ref="high")
t.test(associations ~ type, data=dataSet, alternative="less")
levels(dataSet$type$)
levels(dataSet$type)
t.test(associations ~ type, data=dataSet, alternative="greater")
(mean(dataSet[dataSet$type=="low",]$associations) - mean(dataSet[dataSet$type=="high",]$associations))/sd(dataSet$associations)
(mean(dataSet[dataSet$type=="high",]$associations) - mean(dataSet[dataSet$type=="low",]$associations))/sd(dataSet$associations)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Eddington_and_Ruiz-Mendoza_2010.csv")
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Eddington_and_Ruiz-Mendoza_2010.csv")
ggplot(dataSet, aes(x=condition, y=Mean_RT)) + geom_boxplot()
unique(dataSet$condition)
nrow(dataSet)
ggplot(dataSet[dataSet$condition=="only syntax", ], aes(x=Mean_RT)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$condition=="only syntax", ]$Mean_RT) ), color="red")
ggplot(dataSet[dataSet$condition=="syntax and semantics", ], aes(x=Mean_RT)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$condition=="syntax and semantics", ]$Mean_RT) ), color="red")
shapiro.test(dataSet[dataSet$condition=="only syntax", ]$Mean_RT)
shapiro.test(dataSet[dataSet$condition=="syntax and semantics", ]$Mean_RT)
v
ggplot(dataSet[dataSet$condition=="syntax and semantics", ], aes(x=Mean_RT)) + geom_line(stat="density") + geom_vline(aes(xintercept =mean(dataSet[dataSet$condition=="syntax and semantics", ]$Mean_RT) ), color="red")
dataSet$condition <- as.factor(dataSet$condition)
dataSet$condition <- relevel(dataSet$condition, ref="syntax and semantics")
wilcox.test(Mean_RT ~ condition, data=dataSet, alternative="less", paired=TRUE)
ggplot(dataForPlot, aes(x=type, y=mean, color=type, fill=type)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5, color="grey")
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Paivio_et_al_1968.csv")
dataSet$type <- as.factor(dataSet$type)
dataSet$type <- relevel(dataSet$type, ref="low")
SE<-sd(dataSet$associations)/sqrt(nrow(dataSet))
dataForPlot <- dataSet %>%
group_by(type) %>%
summarise(lowerBound= mean(associations)-(1.96*SE),
upperBound=mean(associations)+(1.96*SE),
mean=mean(associations))
ggplot(dataForPlot, aes(x=type, y=mean, color=type, fill=type)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5, color="grey")
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class4_Eddington_and_Ruiz-Mendoza_2010.csv")
ataForPlot <- dataSet %>%
group_by(condition) %>%
summarise(lowerBound= confMedian(Mean_RT)[1],
upperBound=confMedian(Mean_RT)[2],
median=median(Mean_RT))
ataForPlot
dataSet$condition <- as.factor(dataSet$condition)
dataSet$condition <- relevel(dataSet$condition, ref="syntax and semantics")
dataForPlot <- dataSet %>%
group_by(condition) %>%
summarise(lowerBound= confMedian(Mean_RT)[1],
upperBound=confMedian(Mean_RT)[2],
median=median(Mean_RT))
ggplot(dataForPlot, aes(x=condition, y=mean, color=condition, fill=condition)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5, color="black")
ggplot(dataForPlot, aes(x=condition, y=mean, color=condition, fill=condition)) + geom_bar(stat="identity")
ggplot(dataForPlot, aes(x=condition, y=median, color=condition, fill=condition)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5, color="black")
confMedian <- function(x) {
sort(x)[qbinom(c(.025,.975), length(x), 0.5)]
}
# Convert 'condition' to a factor
dataSet$condition <- as.factor(dataSet$condition)
# Relevel 'condition' so that the reference level is 'syntax and semantics'
dataSet$condition <- relevel(dataSet$condition, ref="syntax and semantics")
# Load the 'dplyr' package
library(dplyr)
# Calculate the data for the plot, including the upper and lower bounds of the confidence intervals:
dataForPlot <- dataSet %>%
group_by(condition) %>%
summarise(lowerBound= confMedian(Mean_RT)[1],
upperBound=confMedian(Mean_RT)[2],
median=median(Mean_RT))
# Load the ggplot2 package
library(ggplot2)
# Create a colored barplot to compare the two group medians in the 'dataForPlot' data.frame.
# Add error bars to the barplot
ggplot(dataForPlot, aes(x=condition, y=median, color=condition, fill=condition)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin=lowerBound, ymax=upperBound), width=0.5, color="black")
library(readr)
