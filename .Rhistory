filter(!duplicated(id_str))
finalSet <- finalSet %>%
mutate(country=ifelse(country %in% c("Puerto Rico", "Panama", "Dominican Republic", "Venezuela"), "Caribbean", country)) %>%
mutate(country=ifelse(country %in% c("Uruguay", "Paraguay"), "Uruguay/Paraguay", country)) %>%
mutate(country=ifelse(country %in% c("United States"), "USA", country))  %>%
arrange(in_reply_to_status_id_str, desc(created_at)) %>%
mutate(queSentence=ifelse(grepl("(^que |^q |^k |^ke |[[:punct:]]que|[[:punct:]]q |[[:punct:]]k |[[:punct:]]ke |^ que|^ q|^ k |^ ke |[[:punct:]] que|[[:punct:]] q |[[:punct:]] k |[[:punct:]] ke |^(@[[:alnum:] ])+que|^(@[[:alnum:] ])+q |^(@[[:alnum:] ])+ke |^(@[[:alnum:] ])+k )", perl=TRUE, ignore.case=TRUE, text), TRUE, FALSE))
View(finalSet)
finalSet <- finalSet %>%
mutate(in_reply_to_text=text[which(id_str==in_reply_to_status_id_str)])
head(finalSet$text[which(finalSet$id_str==finalSet$in_reply_to_status_id_str)])
library(twitteR)
??twitter
??twitteR
library(stringi)
library(dplyr)
library(readr)
library(ggplot2)
library(parallel)
library(ggmap)
# --------------
# Options
# --------------
options(mc.cores=6, scipen = 999, stringsAsFactors = F)
# --------------
# Data
# --------------
dataSet <- read_csv("~/Desktop/twitterCorpus/deliverables/dataSet.csv") %>%
mutate(created_at=stri_replace_all_fixed(created_at, "T", " ")) %>%
mutate(created_at=stri_replace_all_fixed(created_at, "Z", "")) %>%
mutate(created_at=as.POSIXct(created_at, format="%Y-%m-%d %H:%M:%S", origin="1970-01-01", tz="UTC"))
dataSet$geoColumn <- dataSet$geoColumn %>%
stri_replace_all_regex("[^[:alpha:] ]", "") %>%
stri_replace_all_regex("[ ]+", " ") %>%
stri_trans_general(id="latin-ascii") %>%
stri_trans_tolower()
dataSet <- dataSet %>%
mutate(country=ifelse(grepl("(canarias|tenerife|el hierro|el hierro|la palma|la gomera|gran canaria|fuerteventura|lanzarote|santa cruz de tenerife|canaria)", geoColumn, perl=TRUE), "Canarias",ifelse( grepl("(spain|espana|españa|madrid|barcelona|vigo|sevilla|barajas|a coruña|a coruna|toledo|galicia|galiza|gallego|galego|adra|andalucía|valenciana|valencia|andalucia|albacete|zamora|zafra|málaga|malaga|mallorca|menorca|bilbao|vizcaya|guijon|guijón|xixon|xixón|valència|catalunya|catalan|compostela)", geoColumn, perl=TRUE), "Spain", ifelse(grepl("(puerto rico|porto rico|p r|\\bpr\\b|borinquén|borinquen|borinken|borinkén|república dominicana|rep. dominicana|quisqueya|dominican republic|dominican rep|dom rep|r d |dom |cuba|havana|santo domingo|san juan|baranquilla|colombia|panamá|panama|dominicana|venezuela|venezolana|boricua|caribbean|caribe|venezuela|venezolano|aguadilla|barranquilla)", geoColumn, perl=TRUE), "Caribbean", ifelse(grepl("(mexico|méxico|méjico|mejico|monterrey|méx|mex|mx|guanajuato|acapulco|puebla|acatlán|acatlan|acuña|acuna|aguascalientes)", geoColumn, perl=TRUE), "Mexico", ifelse(grepl("(chile|valparaíso|chl|valparaiso)", geoColumn, perl=TRUE), "Chile", ifelse(grepl("(lima|cuzco|cusco|puno|bolivia|potosi|potosí|peru|perú|cali|calí)", geoColumn, perl=TRUE), "Andes",ifelse(grepl("(argentina|mendoza|buenos aires|pampa|ar |\\b(a r g e n t i n a)\\|adrogue|adrogué|agentina|alberdi|cordoba|córdoba|arg )", geoColumn, perl=TRUE), "Argentina",ifelse(grepl("(uruguay|paraguay|montevideo|montevídeo)",perl=TRUE, geoColumn), "Uruguay/Paraguay", ifelse(grepl("(new york|nueva york|\\bny\\b|new orleans|albaquerque|boston|michigan|washington|usa|chicago|west coast|los angeles|palm beach|florida|miami|virginia)", geoColumn, perl=TRUE), "USA", NA))))))))))
geocodes <- read_csv("~/Desktop/twitterCorpus/deliverables/geocodeCache.csv", col_names=c("geoColumn", "country"))
geocoded <- dataSet %>%
filter(!is.na(country))
finalSet <-dataSet %>%
filter(is.na(country)) %>%
select(-country) %>%
left_join(geocodes, by="geoColumn") %>%
bind_rows(geocoded) %>%
filter(!duplicated(id_str))
finalSet <- finalSet %>%
mutate(country=ifelse(country %in% c("Puerto Rico", "Panama", "Dominican Republic", "Venezuela"), "Caribbean", country)) %>%
mutate(country=ifelse(country %in% c("Uruguay", "Paraguay"), "Uruguay/Paraguay", country)) %>%
mutate(country=ifelse(country %in% c("United States"), "USA", country))  %>%
arrange(in_reply_to_status_id_str, desc(created_at)) %>%
mutate(queSentence=ifelse(grepl("(^que |^q |^k |^ke |[[:punct:]]que|[[:punct:]]q |[[:punct:]]k |[[:punct:]]ke |^ que|^ q|^ k |^ ke |[[:punct:]] que|[[:punct:]] q |[[:punct:]] k |[[:punct:]] ke |^(@[[:alnum:] ])+que|^(@[[:alnum:] ])+q |^(@[[:alnum:] ])+ke |^(@[[:alnum:] ])+k )", perl=TRUE, ignore.case=TRUE, text), TRUE, FALSE))
finalSet <- finalSet %>%
mutate(in_reply_to_text=text[which(id_str==in_reply_to_status_id_str)])
finalSet <- finalSet %>%
mutate(in_reply_to_text=ifelse(length(text[which(id_str==in_reply_to_status_id_str)]) > 0, text[which(id_str==in_reply_to_status_id_str)], NA))
View(finalSet)
finalSet <- finalSet %>%
group_by(in_reply_to_status_id_str) %>%
mutate(in_reply_to_text=ifelse(length(text[which(id_str==in_reply_to_status_id_str)]) > 0, text[which(id_str==in_reply_to_status_id_str)], NA))
View(finalSet)
View(finalSet[finalSet$text!=finalSet$in_reply_to_text, ])
bd <- finalSet[finalSet$text!=finalSet$in_reply_to_text, ]
bd <- bd[!is.na(bd$text),]
View(bd)
bd <- bd  %>% group_by(in_reply_to_status_id_str) %>% arrange(desc(created_at))
View(bd)
colnames(bd)
table(bd$country)
load("/Users/jeroenclaes/Google Drive/PostDoc/Papers/haber_twitter_coser/COSER-TWITTER.rdata")
ls()
head(total.data)
View(total.data)
library(stringi)
total.data$characters_before_noun <- stri_length(stri_replace_all_fixed(total.data$after, total.data$noun, ""))
total.data$characters_before_noun <- stri_length(stri_replace_all_fixed(stri_replace_all_regex(total.data$after,"(_[[:alnum:]]+)", ""), total.data$noun, ""))
library(ggplot2)
ggplot(total.data, aes(x=characters_before_noun)) + geom_line(stat="densithy")
ggplot(total.data, aes(x=characters_before_noun)) + geom_line(stat="density")
any(is.na(total.data$characters_before_noun))
total.data<-total.data[!is.na(total.data$characters_before_noun), ]
b <- sample(total.data, 500)
View(total.data)
b<- sample(1:7529, 500)
b
set <- total.data[b,]
View(set)
set$noun_length <- stri_count(set$noun)
set$noun_length <- stri_length(set$noun)
ggplot(set, aes(x=noun_length)) + geom_line(stat="density")
ggplot(set, aes(x=noun_length)) + geom_line(stat="density") + geom_vline(aes(x=mean(set$noun_length)))
ggplot(set, aes(x=noun_length)) + geom_line(stat="density") + geom_vline(aes(xintercept=mean(set$noun_length)))
set %>% arrange(desc(noun_length)) %>% head(10)
library(dplyr)
set %>% arrange(desc(noun_length)) %>% head(10) %>% select(noun, noun_length)
head(set$noun_length)
head(unique(set$noun))
head(unique(set$noun), 20)
dataSet <- set
head(dataSet)
head(dataSet[dataSet$noun_length==6,c("noun")])
tail(dataSet[dataSet$noun_length <= 10,c("noun")],20)
tail(dataSet[dataSet$noun_length < 4,c("noun")],20)
tail(dataSet[dataSet$noun_length < 5,c("noun")],20)
library(ggplot2)
qqnorm(dataSet$characters_before_noun)
qqline(dataSet$characters_before_noun)
shapiro.test(dataSet$characters_before_noun)
ggplot(dataSet, aes(x=characters_before_noun)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$characters_before_noun)))
ggplot(dataSet, aes(x=characters_before_noun)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$characters_before_noun), color="red"))
ggplot(dataSet, aes(x=characters_before_noun)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$characters_before_noun)), color="red")
mean(dataSet$characters_before_noun)
median(dataSet$characters_before_noun)
mean(dataSet$noun_length)
median(dataSet$noun_length)
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$noun_length)), color="red")
shapiro.test(dataSet$noun_length)
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$noun_length)), color="red")
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$noun_length)), color="red")
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
summary(dataSet$noun_length)
IQR(dataSet$noun_length)
summary(dataSet$characters_before_noun)
ggplot(dataSet, aes(x=1/(characters_before_noun+1)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(=1/(characters_before_noun+1))), color="red")
ggplot(dataSet, aes(x=1/(characters_before_noun+1)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(1/(characters_before_noun+1))), color="red")
ggplot(dataSet, aes(x=1/(characters_before_noun+1)) + geom_line(stat="density")
ggplot(dataSet, aes(x=1/(characters_before_noun+1))) + geom_line(stat="density")
ggplot(dataSet, aes(x=log(characters_before_noun+1)) + geom_line(stat="density")
ggplot(dataSet, aes(x=log(characters_before_noun+1))) + geom_line(stat="density")
log(1000)
log10(1000)
exp()
exp(6.907755)
6.907755^2.718281828459
?log
exp(1)
log(1000)^2.718282
2.718282^7
2.718282^0
log10(1000)
10^3
log2(1000)
?exp
exp(3)
exp(3, base=10)
e
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqpline(dataSet$noun_length)
qqline(dataSet$noun_length)
shapiro.test(dataSet$noun_length)
ggplot(dataSet, aes(x=noun_length)) +  geom_line(stat="density")
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
shapiro.test(dataSet$noun_length)
mean(dataSet$noun_length)
median(dataSet$noun_length)
View(dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv"))
dataSet <- set
dataSet$noun_length_zscore <- scale(dataSet$noun_length)
# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density")
ggplot(dataSet, aes(x=noun_length_zscore)) + geom_line(stat="density")
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density")
ggplot(dataSet, aes(x=noun_length_zscore^2)) + geom_line(stat="density")
ggplot(dataSet, aes(x=1/(1+noun_length_zscore))) + geom_line(stat="density")
ggplot(dataSet, aes(x=sqrt(noun_length_zscore))) + geom_line(stat="density")
dataSet$mad_z <- dataSet$noun_length-mad(dataSet$noun_length)/median(dataSet$noun_length)
head(dataSet$mad_z)
summary(dataSet$mad_z)
dataSet$mad_z <- dataSet$noun_length-mad(dataSet$noun_length)/mad(dataSet$noun_length)
head(dataSet$mad_z)
head(set)
nrow(set)
write_csv(set, "../datasets/class3_claes_2017.csv")
library(readr)
write_csv(set, "../datasets/class3_claes_2017.csv")
?read_csv
library(readr)
library(dplyr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
glimpse(dataSet)
dataSet <- mutate_if(dataSet, is.character, as.factor)
?mutate_if
levels(dataSet$type)
dataSet$type <- relevel(dataSet$type, ref="plural")
levels(dataSet$type)
levels(datSet$type)
dataSet$type <- relevel(dataSet$type, ref="plural")
levels(dataSet$type)
?reorder
dataSet$type <- reorder(dataSet$type,dataSet$noun_length)
v
levels(dataSet$type)
dataSet$type <- reorder(dataSet$type,dataSet$noun_length)
levels(dataSet$type)
table(dataSet$type)
str(table(dataSet$type))
b<-table(dataSet$type)
b$
b[[1]]
b[[2]]
tab <- as.data.frame(table(dataSet$type))
tab
prop.table(table(dataSet$type))
prop.table(table(dataSet$type)) *100
prop.table(table(dataSet$type)) * 100
tab <- table(dataSet$type)
tab <- as.data.frame(tab)
tab
tab$proportion <- tab$Freq/sum(tab$Freq)
tab
?recode
?recode_factor
summary(dataSet)
dataSet$broad.regions <- recode(dataSet$broad.regions, 'North'="Top", "East"="Left", "Center"="Middle", "South"="Bottom")
summary(dataSet)
levels(dataSet$broad.regions)
dataSet$broad.regions <- recode(dataSet$broad.regions, "Left"="Middle")
levels(dataSet$type)
levels(dataSet$broad.regions)
ggplot(dataSet, aes(x=type)) + geom_bar()
ggplot(dataSet, aes(x=type)) + geom_bar(position = "fill")
ggplot(dataSet, aes(x=type)) + geom_bar(position = "stack")
ggplot(dataSet, aes(x=type, color=type, fill=type)) + geom_bar()
?stat_summary
?geom_line
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class2_balota_et_al_2007.csv")
ggplot(dataSet, aes(x=Length, y=Mean_RT))  + geom_line(stat="mean")
ggplot(dataSet, aes(x=Length, y=Mean_RT))  + geom_line(stat="stat_summary")
ggplot(dataSet, aes(x=Length, y=Mean_RT))  + geom_line(stat="bin")
ggplot(dataSet, aes(x=Length))  + geom_line(stat="bin")
ggplot(dataSet, aes(x=Length))  + geom_line(stat="density")
tab <- prop.table(table(dataSet$type))
round(tab, 3)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
tab <- prop.table(table(dataSet$type))
round(tab, 3)
round(tab, 2)
tab <- prop.table(table(dataSet$type))
tab
tab <- prop.table(table(dataSet$type))
?prop.table
scales::percent(tab)
sggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal()
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE, fig.height = 4, dpi = 300)
library(pander)
library(readr)
library(dplyr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
library(ggplot2)
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() + theme(axis.text.x = element_text(angle=90))
italic("haha")
library(ggplot2)
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90)) +
labs(x="Type", y="Frequency", title=paste(italic("Haber"), " in Peninsular Spanish"))
library(ggplot2)
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90)) +
labs(x="Type", y="Frequency", title=expression(paste(italic("Haber"), " in Peninsular Spanish")))
library(ggplot2)
titleWithItalics <- expression(paste(italic("Haber"), "in Peninsular Spanish"))
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90)) +
labs(x="Type", y="Frequency", title=titleWithItalics)
library(ggplot2)
titleWithItalics <- expression(paste(italic("Haber "), "in Peninsular Spanish"))
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90)) +
labs(x="Type", y="Frequency", title=titleWithItalics)
library(ggplot2)
titleWithItalics <- expression(paste(italic("Haber"), "in Peninsular Spanish", sep=" "))
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90)) +
labs(x="Type", y="Frequency", title=titleWithItalics)
library(ggplot2)
titleWithItalics <- expression(paste(italic("Haber "), "in Peninsular Spanish"))
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90)) +
labs(x="Type", y="Frequency", title=titleWithItalics)
?expression
library(ggplot2)
ggplot(dataSet, aes(x=type))  +
geom_bar() +
theme_minimal() +
theme(axis.text.x = element_text(angle=90), legend.title = element_blank())
ggplot(dataSet, aes(x=type)) + geom_bar(position="fill")
ggplot(dataSet, aes(x=type, fill=type)) + geom_bar(position="fill")
ggplot(dataSet, aes(x=type, color=type, fill=type, y=(..count..)/sum(..count..))) +
geom_bar(stat="identity") +
theme(legend.title =  element_blank())
library(ggplot2)
ggplot(dataSet, aes(x=type, color=type, fill=type) ) +
geom_bar(aes(y=..count../sum(..count..))) +
theme(legend.title =  element_blank())
ggplot(dataSet, aes(x=type, color=type, fill=type) ) +
geom_bar(aes(y=(..count../sum(..count..))))
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=..counts../sum(..counts..)))
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=(..counts../sum(..counts..))))
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=(..count../sum(..count..))))
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=..count../sum(..count..)))
?geom_bar
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=..count../sum(..count..)), scale) +
scale_y_continuous(labels=percent)
library(scales)
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=..count../sum(..count..)), scale) +
scale_y_continuous(labels=percent)
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
scale_y_continuous(labels=percent)
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
scale_y_continuous(labels=percent) +
theme(legend.title=element_blank())
library(ggplot2)
library(scales)
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
scale_y_continuous(labels=percent) +
theme(legend.title=element_blank()) +
labs(y="Percentages")
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
scale_y_continuous(labels=percent) +
theme(legend.title=element_blank()) +
labs(y="Percentages")
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar()
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar(theta=y)
library(ggplot2)
library(scales)
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar(aes(y=..count../sum(..count..)), theta=y)
library(ggplot2)
library(scales)
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar(aes(y=..count../sum(..count..), theta=y) )
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar(theta="y") )
ggplot(dataSet, aes(x=type, color=type, fill=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar(theta="y")
ggplot(dataSet, aes(x=type))  +
geom_bar(aes(y=..count../sum(..count..))) +
coord_polar(theta="y")
ggplot(dataSet, aes(x=type))  +
geom_bar() +
coord_polar(theta="y")
ggplot(dataSet, aes(fill=type))  +
geom_bar() +
coord_polar(theta="y")
ggplot(dataSet, aes(x=factor(""), fill=type))  +
geom_bar() +
coord_polar(theta="y")
glimpse(dataSet)
dataSet$state <- as.factor(dataSet$state)
dataSet$state <- as.factor(dataSet$state)
levels(state)
levels(dataSet$state )
library(dplyr)
# Convert all character columns to factor
dataSet <- mutate_if(dataSet, is.character, as.factor)
# The state column has quite some duplicates:
# "Andalusia" and "Andalucía" , "Aragon" and "Aragón", "Castile-La Mancha" and "Castilla-La-Mancha", "Castile and León" and "Castilla y León", "Catalonia" and "Cataluña", "Community of Madrid" and "Comunidad de Madrid", "Valencian Community" and "Comunidad Valenciana", "Basque Country" and "País Vasco"
# Recode all Spanish names to the English alternative
dataSet$state<-recode(dataSet$state, "Andalusia"="Andalucía", "Aragon"="Aragón", "Castile-La Mancha"="Castilla-La-Mancha","Castile and León"="Castilla y León", "Catalonia"="Cataluña", "Community of Madrid"="Comunidad de Madrid", "Valencian Community"="Comunidad Valenciana", "Basque Country"="País Vasco")
# Print the new levels of the `state` column
levels(dataSet$state)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
library(dplyr)
# Convert all character columns to factor
dataSet <- mutate_if(dataSet, is.character, as.factor)
levels(dataSet$state)
dataSet$state<-recode(dataSet$state, "Andalusia"="Andalucía", "Aragon"="Aragón", "Castile-La Mancha"="Castilla-La-Mancha","Castile and León"="Castilla y León", "Catalonia"="Cataluña", "Community of Madrid"="Comunidad de Madrid", "Valencian Community"="Comunidad Valenciana", "Basque Country"="País Vasco")
levels(dataSet$state)
dataSet$state<-recode(dataSet$state, "Andalucía"="Andalusia" ,"Aragón" = "Aragon","Castilla-La-Mancha"=  "Castile-La Mancha",  "Castilla y León"="Castile=León",  "Cataluña"="Catalonia", "Comunidad de Madrid"="Community of Madrid", "Comunidad Valenciana"="Valencian Community",  "País Vasco"="Basque Country")
v
levels(dataSet$state)
ggplot(dataSet, aes(x=broad.region, fill=broad.region, color=broad.region)) + geom_bar() + theme(legend.title = element_blank()) + labs(x="Large regions", y="Number of occurrences", title="Number of occurrences per region")
ggplot(dataSet, aes(x=broad.region, fill=broad.region, color=broad.region)) + geom_bar() + theme(legend.title = element_blank()) + labs(x="Large regions", y="Number of occurrences", title="Number of occurrences per region")
prop.table(table(dataSet$corpus))
devtools::install_github("https://github.com/datacamp/testwhat")
devtools::install_github("datacamp/testwhat")
library(testwhat)
?testwhat::check_output_expr
?testwhat::check_output_expr
?testwhat::check_output_expr
?ex()
?test_library_function
?check_output
?check_output_expr
?test_library_function
?check_output_expr
?check_column
?check_column
?test_function
?test_function
?qqnorm
?test_function
?test_ggpplot
?test_ggplot
?test_library_function
??test_object
