---
title: "Class 3: Data frames (recap), normal distribution and outliers (recap), and exploring qualitative variables"
author: "Jeroen Claes | <jeroen.claes@kuleuven.be> | <jeroen@cropland.be>"
---
## 1. Working with data.frames (recap)
### Loading data from CSV
```{r, include=FALSE}
tutorial::go_interactive()
```

```{r ex="create_a", type="sample-code"}
# Load the readr package

# Load the course data from the course website to the object 'dataSet':
# http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv

# Load the dplyr package

# Print a 'glimpse' of the dataSet

```

```{r ex="create_a", type="solution"}
# Load the readr package
library(readr)
# Load the course data from the course website to the object 'dataSet':
# http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
# Load the dplyr package
library(dplyr)
# Print a 'glimpse' of the dataSet
glimpse(dataSet)
```

```{r ex="create_a", type="sct"}
test_object("dataSet")
test_output_contains("glimpse(dataSet)", incorrect_msg = "Make sure to print the last six rows!")
success_msg("Great!")
```

## 2. Working with data.frames (recap)
### Subsetting data.frames (1/4)

```{r ex="explore", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="explore", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Print the first 25 values of its noun column


```

```{r ex="explore", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Print the first 25 values of its noun column
head(dataSet$noun)

```

```{r ex="explore", type="sct"}
test_output_contains("head(dataSet$noun, 25)", incorrect_msg = "Make sure to print the first 25 nouns")
success_msg("Great!")
```

### Subsetting data.frames  (2/4)

```{r ex="explore2", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="explore2", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Print the first 6 values of noun that have noun_length equal to 6

```

```{r ex="explore2", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Print the first 6 values of noun that have noun_length equal to 6
head(dataSet[dataSet$noun_length==6,c("noun")])
```

```{r ex="explore2", type="sct"}
test_output_contains('head(dataSet[dataSet$noun_length==6,c("noun")])', incorrect_msg = "Make sure to print the first sixrows")
success_msg("Great!")
```

### Subsetting data.frames (3/4)
```{r ex="subset1", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="subset1", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Print the last 20  values 'noun' that have a length smaller than 5

# Create a new data.frame, called shortNouns,  which holds all rows and all columns of dataSet, where noun_length is smaller than or equal to 10

# Print the 10th, the thirtieth, and the 100th row of this data.frame


```

```{r ex="subset1", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Print the last 20  values 'noun' that have a length smaller than 5
tail(dataSet[dataSet$noun_length < 5,c("noun")],20)

# Create a new data.frame, called shortNouns,  which holds all rows and all columns of dataSet, where noun_length is smaller than or equal to 10
shortNouns <- dataSet[dataSet$noun_length <= 10,]

# Print the first, the second, and the 50th row of this data.frame
shortNouns[c(10, 30, 100),]
```

```{r ex="subset1", type="sct"}

test_output_contains('tail(dataSet[dataSet$noun_length < 5,c("noun")],20)', incorrect_msg = "Make sure to print the last 20  values of noun")
test_output_contains("shortNouns <- dataSet[dataSet$noun_length <= 10,]", incorrect_msg = "Make sure to make a new dataframe 'shortNouns'")
test_output_contains("shortNouns[c(10, 30, 100),]", incorrect_msg = "Make sure to print the first, the second, and the 50th row of lowFrequency")
success_msg("Great!")
```

### Subsetting data.frames (4/4)
```{r ex="subset2", type="pre-exercise-code"}
library(readr)
library(dplyr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="subset2", type="sample-code"}
# The data.frame dataSet is already in your workspace. 
# The package dplyr is already loaded

# Extract all values of `noun` with noun_length smaller than 5. Print only the first 15  nouns

# Extract the noun_length of the following nouns: "restricciones"  "fotos" "olivas"   "periodistas" "cosechadoras"  

# Add a new variable to the data.frame, called meanLength which stores the mean of noun_length

# Print a summary of the modified data.Frame
```

```{r ex="subset2", type="solution"}
# The data.frame dataSet is already in your workspace. 
# The package dplyr is already loaded

# Extract all values of `noun` with noun_length smaller than 5. Print only the first 15  words
head(dataSet[dataSet$noun_length < 5,]$noun, 15)

# Extract the noun_length of the following nouns: "restricciones"  "fotos" "olivas"   "periodistas" "cosechadoras"  
dataSet[dataSet$Word %in% c("restricciones", "fotos", "olivas", "periodistas","cosechadoras"), c("noun_length")]

# Add a new variable to the data.frame, called FreqByTwo which stores the Freq of the word, divided by two
dataSet$meanLength <- mean(dataSet$noun_length, na.rm=TRUE)

# Print a glimpse of the modified data.Frame
glimpse(dataSet)
```

```{r ex="subset2", type="sct"}
test_output_contains("head(dataSet[dataSet$noun_length < 5,]$noun, 15)", incorrect_msg = "Make sure to print the first couple of values of Freq < 600")
test_output_contains('dataSet[dataSet$Word %in% c("restricciones", "fotos", "olivas", "periodistas","cosechadoras"), c("noun_length")]', incorrect_msg = "Make sure to extract the Length and the Freq of the words in the list")
test_output_contains("dataSet$meanLength", incorrect_msg = "Make sure to create the meanLength variable!")
success_msg("Great job!")
```

## 2. The normal distribution (recap)

- **ANALYZE**:
    - Are the `characters_before_noun` and `noun_length` variables distributed normally?
    - Why do you think so?

### 2.2 The `characters_before_noun` variable 

```{r ex="normal1", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="normal1", type="sample-code"}
# The data.frame dataSet is already in your workspace. 
# Calculate and compare the mean of characters_before_noun to the median of characters_before_noun

# Load the ggplot2 package

# Draw a qqplot with a qqline of the characters_before_noun variable

# Draw a density plot of the characters_before_noun variable

# Perform a Shapiro-Wilk test

# THINK: is the characters_before_noun variable distributed normally? You will find the correct answer on the Solution tab. 

```

```{r ex="normal1", type="solution"}
# The data.frame dataSet is already in your workspace. 
# Calculate and compare the mean of characters_before_noun to the median of characters_before_noun
mean(dataSet$characters_before_noun)
median(dataSet$characters_before_noun)
# Load the ggplot2 package
library(ggplot2)
# Draw a qqplot with a qqline of the characters_before_noun variable
qqnorm(dataSet$characters_before_noun)
qqline(dataSet$characters_before_noun)
# Draw a density plot of the characters_before_noun variable
ggplot(dataSet, aes(x=characters_before_noun)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$characters_before_noun)), color="red")
# Perform a Shapiro-Wilk test
shapiro.test(dataSet$characters_before_noun)
# THINK: is the characters_before_noun variable distributed normally? You will find the correct answer on the Solution tab. 
# The correct answer is no: 
# - The mean and the median are not very closeby numerically
# - The dots do not follow the line in the qqplot
# - The mean is not in the middle of the distribution and the largest amount of values do not occur around the mean
# - The shapiro.test has a p < 0.05
```

```{r ex="normal1", type="sct"}
test_output_contains("mean", incorrect_msg = "Make sure to calculate the mean")
test_output_contains("median", incorrect_msg = "Make sure to calculate the median")
test_output_contains('qqnorm', incorrect_msg = "Make sure to draw a qqplot")
test_output_contains('qqline', incorrect_msg = "Make sure to add a qqpline to your qqplot")
test_output_contains('geom_line', incorrect_msg = "Make sure to draw a density plot")
test_output_contains('geom_vline', incorrect_msg = "Make sure to add a vertical line at the mean")
test_output_contains("shapiro.test", incorrect_msg = "Make sure to perform a Shapiro-Wilk test!")
success_msg("Great job!")
```

### 2.2 The `noun_length` variable

```{r ex="normal2", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="normal2", type="sample-code"}
# The data.frame dataSet is already in your workspace. 
# Calculate and compare the mean of noun_length to the median of noun_length

# Load the ggplot2 package

# Draw a qqplot with a qqline of the noun_length variable

# Draw a density plot of the noun_length variable

# Perform a Shapiro-Wilk test

# THINK: is the noun_length variable distributed normally? You will find the correct answer on the Solution tab. 

```

```{r ex="normal2", type="solution"}
# The data.frame dataSet is already in your workspace. 
# Calculate and compare the mean of noun_length to the median of noun_length
mean(dataSet$noun_length)
median(dataSet$noun_length)
# Load the ggplot2 package
library(ggplot2)
# Draw a qqplot with a qqline of the noun_length variable
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)
# Draw a density plot of the noun_length variable
ggplot(dataSet, aes(x=noun_length)) + geom_line(stat="density") + geom_vline(aes(xintercept = mean(dataSet$noun_length)), color="red")
# Perform a Shapiro-Wilk test
shapiro.test(dataSet$noun_length)
# THINK: is the noun_length variable distributed normally? You will find the correct answer on the Solution tab. 
# The correct answer is no: 
# - The dots at the bottom and the top of the plot do not follow the line in the qqplot
# - The mean is not in the middle of the distribution and the distribution is not symmetrical
# - The shapiro.test has a p < 0.05, so we can assume that the data are not normally distributed
```

```{r ex="normal2", type="sct"}
test_output_contains("mean", incorrect_msg = "Make sure to calculate the mean")
test_output_contains("median", incorrect_msg = "Make sure to calculate the median")
test_output_contains('qqnorm', incorrect_msg = "Make sure to draw a qqplot")
test_output_contains('qqline', incorrect_msg = "Make sure to add a qqpline to your qqplot")
test_output_contains('geom_line', incorrect_msg = "Make sure to draw a density plot")
test_output_contains('geom_vline', incorrect_msg = "Make sure to add a vertical line at the mean")
test_output_contains("shapiro.test", incorrect_msg = "Make sure to perform a Shapiro-Wilk test!")
success_msg("Great job!")
```

## 3. Outliers 
- The previous excercises have shown that:
    - `noun_length` is mostly normally distributed, except for a few outliers in the right tail of the distribution. If we exclude these values, it will be distributed normally
    - `number_of_characters_before_noun` has a power-law distribution. We will need a `logarithmic` transformation to correct its distribution
    
### 3.1 `noun_length`
```{r ex="noun_length_outliers", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="noun_length_outliers", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Add a new column to the dataSet called `noun_length_zscore`, in which you store z-scores for noun_length

# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores

# Remove all outliers. Remember that outliers are values with z-scores of more than two

# Draw a qqplot with a qqline 

# ANALYZE: Does this fix the problem?
```

```{r ex="noun_length_outliers", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Add a new column to the dataSet called `noun_length_zscore`, in which you store z-scores for noun_length
dataSet$noun_length_zscore <- scale(dataSet$noun_length)

# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores
dataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$noun_length_zscore < 2, ]
# Draw a qqplot of noun_length with a qqline 
qqnorm(dataSet$noun_length)
qqline(dataSet$noun_length)

# ANALYZE: Does this fix the problem?
# The distribution is much closer to a normal distribution, but it is still far from ideal

```

```{r ex="noun_length_outliers", type="sct"}
test_output_contains("dataSet$noun_length_zscore", incorrect_msg = "Make sure to add the noun_length_zscore column")
test_output_contains("abs", incorrect_msg = "Make sure to calculate the absolute value of the z-scores")
test_output_contains('scale', incorrect_msg = "Make sure to calculate z-scores")
test_output_contains('qqline', incorrect_msg = "Make sure to add a qqpline to your qqplot")
test_output_contains('qqnorm', incorrect_msg = "Make sure to draw a qqplot")
success_msg("Great job!")
```

### 3.2 `number_of_characters_before_noun` 

```{r ex="number_of_characters_before_noun_outliers", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="number_of_characters_before_noun_outliers", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Add a new column to the dataSet called `number_of_characters_before_noun_zscore`, in which you store z-scores for number_of_characters_before_noun

# Overwrite `number_of_characters_before_noun_zscore` so that it contains the absolute values of the z-scores

# Remove all outliers. Remember that outliers are values with z-scores of more than two

# Draw a qqplot with a qqline 

# ANALYZE: Does this fix the problem?
```

```{r ex="number_of_characters_before_noun_outliers", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Add a new column to the dataSet called `number_of_characters_before_noun_zscore`, in which you store z-scores for number_of_characters_before_noun
dataSet$number_of_characters_before_noun_zscore <- scale(dataSet$number_of_characters_before_noun)

# Overwrite `number_of_characters_before_noun_zscore` so that it contains the absolute values of the z-scores
dataSet$number_of_characters_before_noun_zscore <- abs(dataSet$number_of_characters_before_noun_zscore)
# Remove all outliers. Remember that outliers are values with z-scores of more than two
dataSet <- dataSet[dataSet$number_of_characters_before_noun_zscore < 2, ]
# Draw a qqplot of number_of_characters_before_noun with a qqline 
qqnorm(dataSet$number_of_characters_before_noun)
qqline(dataSet$number_of_characters_before_noun)

# ANALYZE: Does this fix the problem?
# The distribution is much closer to a normal distribution, but it is still far from ideal

```

```{r ex="number_of_characters_before_noun_outliers", type="sct"}
test_output_contains("dataSet$number_of_characters_before_noun_zscore", incorrect_msg = "Make sure to add the number_of_characters_before_noun_zscore column")
test_output_contains("abs", incorrect_msg = "Make sure to calculate the absolute value of the z-scores")
test_output_contains('scale', incorrect_msg = "Make sure to calculate z-scores")
test_output_contains('qqline', incorrect_msg = "Make sure to add a qqpline to your qqplot")
test_output_contains('qqnorm', incorrect_msg = "Make sure to draw a qqplot")
success_msg("Great job!")
```

## 4. Factors 
### 4.1 Factor levels

```{r ex="factors1", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="factors1", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column state to a factor

# Print its levels

```

```{r ex="factors1", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column state to a factor
dataSet$state <- as.factor(dataSet$state)
# Print its levels
levels(dataSet$state )
```

```{r ex="factors1", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('levels', incorrect_msg = "Make sure to print the levels of the factor!")
success_msg("Great!")
```

### 4.2 Recoding factors
```{r ex="factors2", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv") 

```

```{r ex="factors2", type="sample-code"}
# The data.frame dataSet is already in your workspace. 
# Load the dplyr package

# Convert all character columns to factor

# The `state` column has quite some duplicates: 
# "Andalucía" and "Andalusia", "Aragon" and "Aragón", "Castile-La Mancha" and "Castilla-La-Mancha", "Castile and León" and "Castilla y León", "Catalonia" and "Cataluña", "Community of Madrid" and "Comunidad de Madrid", "Valencian Community" and "Comunidad Valenciana", "Basque Country" and "País Vasco"
# Recode all Spanish names to the English alternative

# Print the new levels of the `state` column

```

```{r ex="factors2", type="solution"}
# The data.frame dataSet is already in your workspace. 
# Load the dplyr package
library(dplyr)
# Convert all character columns to factor
dataSet <- mutate_if(dataSet, is.character, as.factor)
# The state column has quite some duplicates: 
# "Andalucía" and "Andalusia" ,"Aragón"  and  "Aragon","Castilla-La-Mancha" and   "Castile-La Mancha",  "Castilla y León" and "Castile and León",  "Cataluña" and "Catalonia", "Comunidad de Madrid" and "Community of Madrid", "Comunidad Valenciana" and "Valencian Community",  "País Vasco" and "Basque Country"
# Recode all Spanish names to the English alternative
dataSet$state<-recode(dataSet$state, "Andalucía"="Andalusia" ,"Aragón" = "Aragon","Castilla-La-Mancha"=  "Castile-La Mancha",  "Castilla y León"="Castile-and-León",  "Cataluña"="Catalonia", "Comunidad de Madrid"="Community of Madrid", "Comunidad Valenciana"="Valencian Community",  "País Vasco"="Basque Country")
# Print the new levels of the `state` column
levels(dataSet$state)
```

```{r ex="factors2", type="sct"}
test_output_contains('dplyr', incorrect_msg = "Make sure to load the dplyr package!")
test_output_contains('mutate_if', incorrect_msg = "Make sure to convert all character columns to factor!")
test_output_contains('recode', incorrect_msg = "Make sure to recode the factor 'state'!")
success_msg("Great!")
```

### 4.3 Re-organizing factors

```{r ex="factors3", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="factors3", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor

# Print its levels

# Relevel the corpus factor: its first value should be 'Twitter'

```

```{r ex="factors3", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor
dataSet$corpus <- as.factor(dataSet$corpus)
# Print its levels
levels(dataSet$corpus )
# Relevel the corpus factor: its first value should be 'Twitter'
dataSet$corpus <- relevel(dataSet$corpus, ref="Twitter")
```

```{r ex="factors3", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('levels', incorrect_msg = "Make sure to print the levels of the factor!")
test_output_contains('relevel', incorrect_msg = "Make sure to reorder the levels of the factor!")
success_msg("Great!")
```

## 5. Frequencies: counting values
### 5.1 Counting the `negation` variable 
```{r ex="counts_negation", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="counts_negation", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column negation to a factor

# Compute a table for the negation variable, store it in the variable 'negationTab'

# Convert 'negationTab' to a data.frame

# Print 'negationTab'


```

```{r ex="counts_negation", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column negation to a factor
dataSet$negation<-as.factor(dataSet$negation)
# Compute a table for the negation variable, store it in the variable 'negationTab'
negationTab<-table(dataSet$negation)
# Convert 'negationTab' to a data.frame
negationTab<-as.data.frame(negationTab)
# Print 'negationTab'
negationTab
```

```{r ex="counts_negation", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to compute the table!")
test_output_contains('as.data.frame', incorrect_msg = "Make sure to convert the table to a data.frame!")
success_msg("Great!")
```

### 5.2 Counting the `province` variable 
```{r ex="counts_province", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="counts_province", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column province to a factor

# Compute a table for the province variable, store it in the variable 'provinceTab'

# Convert 'provinceTab' to a data.frame

# Print 'provinceTab'


```

```{r ex="counts_province", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column province to a factor
dataSet$province<-as.factor(dataSet$province)
# Compute a table for the province variable, store it in the variable 'provinceTab'
provinceTab<-table(dataSet$province)
# Convert 'provinceTab' to a data.frame
provinceTab<-as.data.frame(provinceTab)
# Print 'provinceTab'
provinceTab
```

```{r ex="counts_province", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to compute the table!")
test_output_contains('as.data.frame', incorrect_msg = "Make sure to convert the table to a data.frame!")
success_msg("Great!")
```

### 5.3 Counting the `Typical.Action.Chain.Pos` variable 
```{r ex="counts_Typical.Action.Chain.Pos", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="counts_Typical.Action.Chain.Pos", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column Typical.Action.Chain.Pos to a factor

# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'

# Convert 'Typical.Action.Chain.PosTab' to a data.frame

# Print 'Typical.Action.Chain.PosTab'


```

```{r ex="counts_Typical.Action.Chain.Pos", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column Typical.Action.Chain.Pos to a factor
dataSet$Typical.Action.Chain.Pos<-as.factor(dataSet$Typical.Action.Chain.Pos)
# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'
Typical.Action.Chain.PosTab<-table(dataSet$Typical.Action.Chain.Pos)
# Convert 'Typical.Action.Chain.PosTab' to a data.frame
Typical.Action.Chain.PosTab<-as.data.frame(Typical.Action.Chain.PosTab)
# Print 'Typical.Action.Chain.PosTab'
Typical.Action.Chain.PosTab
```

```{r ex="counts_Typical.Action.Chain.Pos", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to compute the table!")
test_output_contains('as.data.frame', incorrect_msg = "Make sure to convert the table to a data.frame!")
success_msg("Great!")
```


## 6. Proportions
### 6.1 Proportions for the `Typical.Action.Chain.Pos` variable 
```{r ex="proportionsTypical.Action.Chain.Pos", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="proportionsTypical.Action.Chain.Pos", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column Typical.Action.Chain.Pos to a factor

# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'

# Compute proportions for that table

# Print 'Typical.Action.Chain.PosTab'


```

```{r ex="proportionsTypical.Action.Chain.Pos", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column Typical.Action.Chain.Pos to a factor
dataSet$Typical.Action.Chain.Pos<-as.factor(dataSet$Typical.Action.Chain.Pos)
# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'
Typical.Action.Chain.PosTab<-table(dataSet$Typical.Action.Chain.Pos)
# Convert 'Typical.Action.Chain.PosTab' to a data.frame
Typical.Action.Chain.PosTab<-prop.table(Typical.Action.Chain.PosTab)
# Print 'Typical.Action.Chain.PosTab'
Typical.Action.Chain.PosTab
```

```{r ex="proportionsTypical.Action.Chain.Pos", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to compute the table!")
test_output_contains('prop.table', incorrect_msg = "Make sure to compute proportions for the table!")
success_msg("Great!")
```

### 6.2 Proportions for the `corpus` variable 
```{r ex="proportionscorpus", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="proportionscorpus", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor

# Compute a table for the corpus variable, store it in the variable 'corpusTab'

# Convert the corpusTab object to a data.frame 

# Compute proportions based on the Freq column of that data.frame. Store the proportionsin a new column called 'prop'

# Print corpusTab

```

```{r ex="proportionscorpus", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor
dataSet$corpus<-as.factor(dataSet$corpus)
# Compute a table for the corpus variable, store it in the variable 'corpusTab'
corpusTab<-table(dataSet$corpus)
# Convert 'corpusTab' to a data.frame
corpusTab<-as.data.frame(corpusTab)
# Compute proportions based on the Freq column of that data.frame. Store the proportionsin a new column called 'prop'
corpusTab$prop<-corpusTab$Freq/sum(corpusTab$Freq, na.rm=TRUE)
# Print corpusTab
corpusTab
```

```{r ex="proportionscorpus", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to compute the table!")
test_output_contains('as.data.frame', incorrect_msg = "Make sure to convert the table to a data.frame!")
test_output_contains('sum', incorrect_msg = "Make sure to compute the proportions!")
success_msg("Great!")
```

### 6.3 Proportions for the `broad.regions` variable 
```{r ex="proportionsbroad.regions", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="proportionsbroad.regions", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor

# Compute a table for the broad.regions variable, store it in the variable 'broad.regionsTab'

# Compute proportions for the table. Overwrite the broad.regionsTab object

# Multiply the proportions by 100

# Round to 2 decimals

# Print


```

```{r ex="proportionsbroad.regions", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor
dataSet$broad.regions<-as.factor(dataSet$broad.regions)
# Compute a table for the broad.regions variable, store it in the variable 'broad.regionsTab'
broad.regionsTab<-table(dataSet$broad.regions)
# Compute proportions for the table. Overwrite the broad.regionsTab object
broad.regionsTab<-prop.table(dataSet$broad.regions)
# Multiply the proportions by 100
broad.regionsTab<-broad.regionsTab*100
# Round to 2 decimals
broad.regionsTab<-round(broad.regionsTab, 2)
# Print
broad.regionsTab
```

```{r ex="proportionsbroad.regions", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to compute the table!")
test_output_contains('round', incorrect_msg = "Make sure to round the proportions to 2 decimals!")
test_output_contains('prop.table', incorrect_msg = "Make sure to compute the proportions!")
test_output_contains('100', incorrect_msg = "Make sure to multiply the proportions by 100!")
success_msg("Great!")
```

## 7. Bar plots for Freq
### 7.1 Exploring the counts of the `corpus` variable (1/2)
- **ANALYZE**:
      - Which corpus provided the most examples?

```{r ex="freq1", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="freq1", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor

# Print a table of the number of times 'COSER' and 'Twitter' occur

```

```{r ex="freq1", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor
dataSet$corpus<-as.factor(dataSet$corpus)

# Print a table of the number of times 'COSER' and 'Twitter' occ
table(dataSet$corpus)
```

```{r ex="freq1", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to print the table!")

success_msg("Great!")
```

### 7.1 Exploring the counts of the `corpus` variable (2/2)
```{r ex="freq2", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="freq2", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor

# Load ggplot2

# Draw a basic bar chart of the corpus factor

```

```{r ex="freq2", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor
dataSet$corpus<-as.factor(dataSet$corpus)
# Load ggplot2
library(ggplot2)
# Draw a basic bar chart of the corpus factor
ggplot(dataSet, aes(x=corpus)) + geom_bar()
```

```{r ex="freq2", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('geom_bar', incorrect_msg = "Make sure to draw the bar chart!")

success_msg("Great!")
```

### 7.2 Exploring the counts of the `broad.regions` variable (1/2)
- **ANALYZE**:
    - Which broad.regions provided the most examples?

```{r ex="broad.regions_1", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="broad.regions_1", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor

# Print a table of the number of times 'COSER' and 'Twitter' occur

```

```{r ex="broad.regions_1", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor
dataSet$broad.regions<-as.factor(dataSet$broad.regions)

# Print a table of the number of occurrences that were provided by each region
table(dataSet$broad.regions)
```

```{r ex="broad.regions_1", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to print the table!")

success_msg("Great!")
```

### 7.2 Exploring the counts of the `broad.regions` variable (2/2)
```{r ex="broad.regions", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="broad.regions", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor

# Load ggplot2

# Draw a pretty bar chart of the broad.regions factor: each region has its own fill and color, there is no legend title, the Y axis title is "Number of occurrences", the X axis title is "Large regions", the plot title is "Number of occurrences per region"

```

```{r ex="broad.regions", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor
dataSet$broad.regions<-as.factor(dataSet$broad.regions)
# Load ggplot2
library(ggplot2)
# Draw a basic bar chart of the broad.regions factor
ggplot(dataSet, aes(x=broad.regions, fill=broad.regions, color=broad.regions)) + geom_bar() + theme(legend.title = element_blank()) + labs(x="Large regions", y="Number of occurrences", title="Number of occurrences per region")
```

```{r ex="broad.regions", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('geom_bar', incorrect_msg = "Make sure to draw the bar chart!")

success_msg("Great!")
```

### 7.3 Exploring the the counts of the `negation` variable 
- **ANALYZE**:
    - Do tokens with and without negation occur with equal frequency?
    
```{r ex="negation", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="negation", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column negation to a factor

# Print a table of the negation column

# Load ggplot2

# Draw a pretty bar chart of the negation factor: each value has its own fill and color, there is no legend title, the Y axis title is "Number of occurrences", the X axis title is "Absence/presence of negation", the plot title is "Number of occurrences per Absence/presence of negation"

```

```{r ex="negation", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column negation to a factor
dataSet$negation<-as.factor(dataSet$negation)
# Print a table of the negation column
table(dataSet$negation)
# Load ggplot2
library(ggplot2)
# Draw a basic bar chart of the negation factor
ggplot(dataSet, aes(x=negation, fill=negation, color=negation)) + geom_bar() + theme(legend.title = element_blank()) + labs(x="Large regions", y="Number of occurrences", title="Number of occurrences per region")
```

```{r ex="negation", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to print a table of the column!")
test_output_contains('geom_bar', incorrect_msg = "Make sure to draw the bar chart!")

success_msg("Great!")
```

### 7.4 Exploring the proportions of the `corpus` variable (1/2)
- **ANALYZE**:
    - Which corpus provided the most examples?

```{r ex="freq1_prop", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="freq1_prop", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor

# Print a table of the proportions of 'COSER' and 'Twitter' 

```

```{r ex="freq1_prop", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor
dataSet$corpus<-as.factor(dataSet$corpus)

# Print a table of the proportions of 'COSER' and 'Twitter' 
prop.table(table(dataSet$corpus))
```

```{r ex="freq1_prop", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to print the table!")

success_msg("Great!")
```

### 7.4 Exploring the proportions of the `corpus` variable (2/2)
```{r ex="freq2", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="freq2", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor

# Load ggplot2

# Draw a basic bar chart of the proportions of the corpus factor

```

```{r ex="freq2", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column corpus to a factor
dataSet$corpus<-as.factor(dataSet$corpus)
# Load ggplot2
library(ggplot2)
# Draw a basic bar chart of the proportions of the corpus factor
ggplot(dataSet, aes(x=corpus)) + geom_bar(aes(y=..count../sum(..count..)))
```

```{r ex="freq2", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('geom_bar', incorrect_msg = "Make sure to draw the bar chart!")

success_msg("Great!")
```

### 7.5 Exploring the proportions of the `broad.regions` variable (1/2)
- **ANALYZE**:
    - Which broad.regions provided the most examples?

```{r ex="broad.regions_1", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="broad.regions_1", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor

# Print a table of the number of times 'COSER' and 'Twitter' occur

```

```{r ex="broad.regions_1", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor
dataSet$broad.regions<-as.factor(dataSet$broad.regions)

# Print a table of the number of occurrences that were provided by each region
table(dataSet$broad.regions)
```

```{r ex="broad.regions_1", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to print the table!")

success_msg("Great!")
```

### 7.5 Exploring the proportions of the `broad.regions` variable (2/2)
```{r ex="broad.regions_prop", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="broad.regions_prop", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor

# Load ggplot2

# Draw a pretty bar chart of the proportions of the broad.regions factor: each region has its own fill and color, there is no legend title, the Y axis title is "Number of occurrences", the X axis title is "Large regions", the plot title is "Number of occurrences per region"

```

```{r ex="broad.regions_prop", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column broad.regions to a factor
dataSet$broad.regions<-as.factor(dataSet$broad.regions)
# Load ggplot2
library(ggplot2)
# Draw a basic bar chart of the proportions of the broad.regions factor
ggplot(dataSet, aes(x=broad.regions, fill=broad.regions, color=broad.regions)) + geom_bar(aes(y=..count../sum(..count..))) + theme(legend.title = element_blank()) + labs(x="Large regions", y="Number of occurrences", title="Number of occurrences per region")
```

```{r ex="broad.regions_prop", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('geom_bar', incorrect_msg = "Make sure to draw the bar chart!")

success_msg("Great!")
```

### 7.6 Exploring the the proportions of the `negation` variable 
- **ANALYZE**:
    - Do tokens with and without negation occur with equal frequency?

```{r ex="negation_prop", type="pre-exercise-code"}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
```

```{r ex="negation_prop", type="sample-code"}
# The data.frame dataSet is already in your workspace. 

# Convert the column negation to a factor

# Print a table of the negation column

# Load ggplot2

# Draw a pretty bar chart of the proportions of the negation factor: each value has its own fill and color, there is no legend title, the Y axis title is "Number of occurrences", the X axis title is "Absence/presence of negation", the plot title is "Number of occurrences per Absence/presence of negation"

```

```{r ex="negation_prop", type="solution"}
# The data.frame dataSet is already in your workspace. 

# Convert the column negation to a factor
dataSet$negation<-as.factor(dataSet$negation)
# Print a table of the negation column
table(dataSet$negation)
# Load ggplot2
library(ggplot2)
# Draw a basic bar chart of the proportions of the negation factor
ggplot(dataSet, aes(x=negation, fill=negation, color=negation)) + geom_bar(aes(y=..count../sum(..count..))) + theme(legend.title = element_blank()) + labs(x="Large regions", y="Number of occurrences", title="Number of occurrences per region")
```

```{r ex="negation_prop", type="sct"}
test_output_contains('as.factor', incorrect_msg = "Make sure to convert the column to a factor!")
test_output_contains('table', incorrect_msg = "Make sure to print a table of the column!")
test_output_contains('geom_bar', incorrect_msg = "Make sure to draw the bar chart!")

success_msg("Great!")
```

