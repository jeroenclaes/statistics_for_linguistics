{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Class 3: Data frames (recap), normal distribution and outliers (recap), and exploring qualitative variables\"\nauthor: \"Jeroen Claes | <jeroen.claes@kuleuven.be> | <jeroen@cropland.be>\"\n---\n## 1. Working with data.frames (recap)\n### Loading data from CSV\n```{r, include=FALSE}\ntutorial::go_interactive()\n```\n\n```{r ex=\"create_a\", type=\"sample-code\"}\n# Load the readr package\n\n# Load the course data from the course website to the object 'dataSet':\n# http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\n\n# Load the dplyr package\n\n# Print a 'glimpse' of the dataSet\n\n```\n\n```{r ex=\"create_a\", type=\"solution\"}\n# Load the readr package\nlibrary(readr)\n# Load the course data from the course website to the object 'dataSet':\n# http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n# Load the dplyr package\nlibrary(dplyr)\n# Print a 'glimpse' of the dataSet\nglimpse(dataSet)\n```\n\n```{r ex=\"create_a\", type=\"sct\"}\ntest_object(\"dataSet\")\ntest_output_contains(\"glimpse(dataSet)\", incorrect_msg = \"Make sure to print the last six rows!\")\nsuccess_msg(\"Great!\")\n```\n\n## 2. Working with data.frames (recap)\n### Subsetting data.frames (1/4)\n\n```{r ex=\"explore\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"explore\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Print the first 25 values of its noun column\n\n\n```\n\n```{r ex=\"explore\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Print the first 25 values of its noun column\nhead(dataSet$noun)\n\n```\n\n```{r ex=\"explore\", type=\"sct\"}\ntest_output_contains(\"head(dataSet$noun, 25)\", incorrect_msg = \"Make sure to print the first 25 nouns\")\nsuccess_msg(\"Great!\")\n```\n\n### Subsetting data.frames  (2/4)\n\n```{r ex=\"explore2\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"explore2\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Print the first 6 values of noun that have noun_length equal to 6\n\n```\n\n```{r ex=\"explore2\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Print the first 6 values of noun that have noun_length equal to 6\nhead(dataSet[dataSet$noun_length==6,c(\"noun\")])\n```\n\n```{r ex=\"explore2\", type=\"sct\"}\ntest_output_contains('head(dataSet[dataSet$noun_length==6,c(\"noun\")])', incorrect_msg = \"Make sure to print the first sixrows\")\nsuccess_msg(\"Great!\")\n```\n\n### Subsetting data.frames (3/4)\n```{r ex=\"subset1\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"subset1\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Print the last 20  values 'noun' that have a length smaller than 5\n\n# Create a new data.frame, called shortNouns,  which holds all rows and all columns of dataSet, where noun_length is smaller than or equal to 10\n\n# Print the 10th, the thirtieth, and the 100th row of this data.frame\n\n\n```\n\n```{r ex=\"subset1\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Print the last 20  values 'noun' that have a length smaller than 5\ntail(dataSet[dataSet$noun_length < 5,c(\"noun\")],20)\n\n# Create a new data.frame, called shortNouns,  which holds all rows and all columns of dataSet, where noun_length is smaller than or equal to 10\nshortNouns <- dataSet[dataSet$noun_length <= 10,]\n\n# Print the first, the second, and the 50th row of this data.frame\nshortNouns[c(10, 30, 100),]\n```\n\n```{r ex=\"subset1\", type=\"sct\"}\n\ntest_output_contains('tail(dataSet[dataSet$noun_length < 5,c(\"noun\")],20)', incorrect_msg = \"Make sure to print the last 20  values of noun\")\ntest_output_contains(\"shortNouns <- dataSet[dataSet$noun_length <= 10,]\", incorrect_msg = \"Make sure to make a new dataframe 'shortNouns'\")\ntest_output_contains(\"shortNouns[c(10, 30, 100),]\", incorrect_msg = \"Make sure to print the first, the second, and the 50th row of lowFrequency\")\nsuccess_msg(\"Great!\")\n```\n\n### Subsetting data.frames (4/4)\n```{r ex=\"subset2\", type=\"pre-exercise-code\"}\nlibrary(readr)\nlibrary(dplyr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"subset2\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n# The package dplyr is already loaded\n\n# Extract all values of `noun` with noun_length smaller than 5. Print only the first 15  nouns\n\n# Extract the noun_length of the following nouns: \"restricciones\"  \"fotos\" \"olivas\"   \"periodistas\" \"cosechadoras\"  \n\n# Add a new variable to the data.frame, called meanLength which stores the mean of noun_length\n\n# Print a summary of the modified data.Frame\n```\n\n```{r ex=\"subset2\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n# The package dplyr is already loaded\n\n# Extract all values of `noun` with noun_length smaller than 5. Print only the first 15  words\nhead(dataSet[dataSet$noun_length < 5,]$noun, 15)\n\n# Extract the noun_length of the following nouns: \"restricciones\"  \"fotos\" \"olivas\"   \"periodistas\" \"cosechadoras\"  \ndataSet[dataSet$Word %in% c(\"restricciones\", \"fotos\", \"olivas\", \"periodistas\",\"cosechadoras\"), c(\"noun_length\")]\n\n# Add a new variable to the data.frame, called FreqByTwo which stores the Freq of the word, divided by two\ndataSet$meanLength <- mean(dataSet$noun_length, na.rm=TRUE)\n\n# Print a glimpse of the modified data.Frame\nglimpse(dataSet)\n```\n\n```{r ex=\"subset2\", type=\"sct\"}\ntest_output_contains(\"head(dataSet[dataSet$noun_length < 5,]$noun, 15)\", incorrect_msg = \"Make sure to print the first couple of values of Freq < 600\")\ntest_output_contains('dataSet[dataSet$Word %in% c(\"restricciones\", \"fotos\", \"olivas\", \"periodistas\",\"cosechadoras\"), c(\"noun_length\")]', incorrect_msg = \"Make sure to extract the Length and the Freq of the words in the list\")\ntest_output_contains(\"dataSet$meanLength\", incorrect_msg = \"Make sure to create the meanLength variable!\")\nsuccess_msg(\"Great job!\")\n```\n\n## 2. The normal distribution (recap)\n\n- **ANALYZE**:\n    - Are the `characters_before_noun` and `noun_length` variables distributed normally?\n    - Why do you think so?\n\n### 2.2 The `characters_before_noun` variable \n\n```{r ex=\"normal1\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"normal1\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n# Calculate and compare the mean of characters_before_noun to the median of characters_before_noun\n\n# Load the ggplot2 package\n\n# Draw a qqplot with a qqline of the characters_before_noun variable\n\n# Draw a density plot of the characters_before_noun variable\n\n# Perform a Shapiro-Wilk test\n\n# THINK: is the characters_before_noun variable distributed normally? You will find the correct answer on the Solution tab. \n\n```\n\n```{r ex=\"normal1\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n# Calculate and compare the mean of characters_before_noun to the median of characters_before_noun\nmean(dataSet$characters_before_noun)\nmedian(dataSet$characters_before_noun)\n# Load the ggplot2 package\nlibrary(ggplot2)\n# Draw a qqplot with a qqline of the characters_before_noun variable\nqqnorm(dataSet$characters_before_noun)\nqqline(dataSet$characters_before_noun)\n# Draw a density plot of the characters_before_noun variable\nggplot(dataSet, aes(x=characters_before_noun)) + geom_line(stat=\"density\") + geom_vline(aes(xintercept = mean(dataSet$characters_before_noun)), color=\"red\")\n# Perform a Shapiro-Wilk test\nshapiro.test(dataSet$characters_before_noun)\n# THINK: is the characters_before_noun variable distributed normally? You will find the correct answer on the Solution tab. \n# The correct answer is no: \n# - The mean and the median are not very closeby numerically\n# - The dots do not follow the line in the qqplot\n# - The mean is not in the middle of the distribution and the largest amount of values do not occur around the mean\n# - The shapiro.test has a p < 0.05\n```\n\n```{r ex=\"normal1\", type=\"sct\"}\ntest_output_contains(\"mean\", incorrect_msg = \"Make sure to calculate the mean\")\ntest_output_contains(\"median\", incorrect_msg = \"Make sure to calculate the median\")\ntest_output_contains('qqnorm', incorrect_msg = \"Make sure to draw a qqplot\")\ntest_output_contains('qqline', incorrect_msg = \"Make sure to add a qqpline to your qqplot\")\ntest_output_contains('geom_line', incorrect_msg = \"Make sure to draw a density plot\")\ntest_output_contains('geom_vline', incorrect_msg = \"Make sure to add a vertical line at the mean\")\ntest_output_contains(\"shapiro.test\", incorrect_msg = \"Make sure to perform a Shapiro-Wilk test!\")\nsuccess_msg(\"Great job!\")\n```\n\n### 2.2 The `noun_length` variable\n\n```{r ex=\"normal2\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"normal2\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n# Calculate and compare the mean of noun_length to the median of noun_length\n\n# Load the ggplot2 package\n\n# Draw a qqplot with a qqline of the noun_length variable\n\n# Draw a density plot of the noun_length variable\n\n# Perform a Shapiro-Wilk test\n\n# THINK: is the noun_length variable distributed normally? You will find the correct answer on the Solution tab. \n\n```\n\n```{r ex=\"normal2\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n# Calculate and compare the mean of noun_length to the median of noun_length\nmean(dataSet$noun_length)\nmedian(dataSet$noun_length)\n# Load the ggplot2 package\nlibrary(ggplot2)\n# Draw a qqplot with a qqline of the noun_length variable\nqqnorm(dataSet$noun_length)\nqqline(dataSet$noun_length)\n# Draw a density plot of the noun_length variable\nggplot(dataSet, aes(x=noun_length)) + geom_line(stat=\"density\") + geom_vline(aes(xintercept = mean(dataSet$noun_length)), color=\"red\")\n# Perform a Shapiro-Wilk test\nshapiro.test(dataSet$noun_length)\n# THINK: is the noun_length variable distributed normally? You will find the correct answer on the Solution tab. \n# The correct answer is no: \n# - The dots at the bottom and the top of the plot do not follow the line in the qqplot\n# - The mean is not in the middle of the distribution and the distribution is not symmetrical\n# - The shapiro.test has a p < 0.05, so we can assume that the data are not normally distributed\n```\n\n```{r ex=\"normal2\", type=\"sct\"}\ntest_output_contains(\"mean\", incorrect_msg = \"Make sure to calculate the mean\")\ntest_output_contains(\"median\", incorrect_msg = \"Make sure to calculate the median\")\ntest_output_contains('qqnorm', incorrect_msg = \"Make sure to draw a qqplot\")\ntest_output_contains('qqline', incorrect_msg = \"Make sure to add a qqpline to your qqplot\")\ntest_output_contains('geom_line', incorrect_msg = \"Make sure to draw a density plot\")\ntest_output_contains('geom_vline', incorrect_msg = \"Make sure to add a vertical line at the mean\")\ntest_output_contains(\"shapiro.test\", incorrect_msg = \"Make sure to perform a Shapiro-Wilk test!\")\nsuccess_msg(\"Great job!\")\n```\n\n## 3. Outliers \n- The previous excercises have shown that:\n    - `noun_length` is mostly normally distributed, except for a few outliers in the right tail of the distribution. If we exclude these values, it will be distributed normally\n    - `number_of_characters_before_noun` has a power-law distribution. We will need a `logarithmic` transformation to correct its distribution\n    \n### 3.1 `noun_length`\n```{r ex=\"noun_length_outliers\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"noun_length_outliers\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Add a new column to the dataSet called `noun_length_zscore`, in which you store z-scores for noun_length\n\n# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores\n\n# Remove all outliers. Remember that outliers are values with z-scores of more than two\n\n# Draw a qqplot with a qqline \n\n# ANALYZE: Does this fix the problem?\n```\n\n```{r ex=\"noun_length_outliers\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Add a new column to the dataSet called `noun_length_zscore`, in which you store z-scores for noun_length\ndataSet$noun_length_zscore <- scale(dataSet$noun_length)\n\n# Overwrite `noun_length_zscore` so that it contains the absolute values of the z-scores\ndataSet$noun_length_zscore <- abs(dataSet$noun_length_zscore)\n# Remove all outliers. Remember that outliers are values with z-scores of more than two\ndataSet <- dataSet[dataSet$noun_length_zscore < 2, ]\n# Draw a qqplot of noun_length with a qqline \nqqnorm(dataSet$noun_length)\nqqline(dataSet$noun_length)\n\n# ANALYZE: Does this fix the problem?\n# The distribution is much closer to a normal distribution, but it is still far from ideal\n\n```\n\n```{r ex=\"noun_length_outliers\", type=\"sct\"}\ntest_output_contains(\"dataSet$noun_length_zscore\", incorrect_msg = \"Make sure to add the noun_length_zscore column\")\ntest_output_contains(\"abs\", incorrect_msg = \"Make sure to calculate the absolute value of the z-scores\")\ntest_output_contains('scale', incorrect_msg = \"Make sure to calculate z-scores\")\ntest_output_contains('qqline', incorrect_msg = \"Make sure to add a qqpline to your qqplot\")\ntest_output_contains('qqnorm', incorrect_msg = \"Make sure to draw a qqplot\")\nsuccess_msg(\"Great job!\")\n```\n\n### 3.2 `number_of_characters_before_noun` \n\n```{r ex=\"number_of_characters_before_noun_outliers\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"number_of_characters_before_noun_outliers\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Add a new column to the dataSet called `number_of_characters_before_noun_zscore`, in which you store z-scores for number_of_characters_before_noun\n\n# Overwrite `number_of_characters_before_noun_zscore` so that it contains the absolute values of the z-scores\n\n# Remove all outliers. Remember that outliers are values with z-scores of more than two\n\n# Draw a qqplot with a qqline \n\n# ANALYZE: Does this fix the problem?\n```\n\n```{r ex=\"number_of_characters_before_noun_outliers\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Add a new column to the dataSet called `number_of_characters_before_noun_zscore`, in which you store z-scores for number_of_characters_before_noun\ndataSet$number_of_characters_before_noun_zscore <- scale(dataSet$number_of_characters_before_noun)\n\n# Overwrite `number_of_characters_before_noun_zscore` so that it contains the absolute values of the z-scores\ndataSet$number_of_characters_before_noun_zscore <- abs(dataSet$number_of_characters_before_noun_zscore)\n# Remove all outliers. Remember that outliers are values with z-scores of more than two\ndataSet <- dataSet[dataSet$number_of_characters_before_noun_zscore < 2, ]\n# Draw a qqplot of number_of_characters_before_noun with a qqline \nqqnorm(dataSet$number_of_characters_before_noun)\nqqline(dataSet$number_of_characters_before_noun)\n\n# ANALYZE: Does this fix the problem?\n# The distribution is much closer to a normal distribution, but it is still far from ideal\n\n```\n\n```{r ex=\"number_of_characters_before_noun_outliers\", type=\"sct\"}\ntest_output_contains(\"dataSet$number_of_characters_before_noun_zscore\", incorrect_msg = \"Make sure to add the number_of_characters_before_noun_zscore column\")\ntest_output_contains(\"abs\", incorrect_msg = \"Make sure to calculate the absolute value of the z-scores\")\ntest_output_contains('scale', incorrect_msg = \"Make sure to calculate z-scores\")\ntest_output_contains('qqline', incorrect_msg = \"Make sure to add a qqpline to your qqplot\")\ntest_output_contains('qqnorm', incorrect_msg = \"Make sure to draw a qqplot\")\nsuccess_msg(\"Great job!\")\n```\n\n## 4. Factors \n### 4.1 Factor levels\n\n```{r ex=\"factors1\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"factors1\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column state to a factor\n\n# Print its levels\n\n```\n\n```{r ex=\"factors1\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column state to a factor\ndataSet$state <- as.factor(dataSet$state)\n# Print its levels\nlevels(dataSet$state )\n```\n\n```{r ex=\"factors1\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('levels', incorrect_msg = \"Make sure to print the levels of the factor!\")\nsuccess_msg(\"Great!\")\n```\n\n### 4.2 Recoding factors\n```{r ex=\"factors2\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\") \n\n```\n\n```{r ex=\"factors2\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n# Load the dplyr package\n\n# Convert all character columns to factor\n\n# The `state` column has quite some duplicates: \n# \"Andalucía\" and \"Andalusia\", \"Aragon\" and \"Aragón\", \"Castile-La Mancha\" and \"Castilla-La-Mancha\", \"Castile and León\" and \"Castilla y León\", \"Catalonia\" and \"Cataluña\", \"Community of Madrid\" and \"Comunidad de Madrid\", \"Valencian Community\" and \"Comunidad Valenciana\", \"Basque Country\" and \"País Vasco\"\n# Recode all Spanish names to the English alternative\n\n# Print the new levels of the `state` column\n\n```\n\n```{r ex=\"factors2\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n# Load the dplyr package\nlibrary(dplyr)\n# Convert all character columns to factor\ndataSet <- mutate_if(dataSet, is.character, as.factor)\n# The state column has quite some duplicates: \n# \"Andalucía\" and \"Andalusia\" ,\"Aragón\"  and  \"Aragon\",\"Castilla-La-Mancha\" and   \"Castile-La Mancha\",  \"Castilla y León\" and \"Castile and León\",  \"Cataluña\" and \"Catalonia\", \"Comunidad de Madrid\" and \"Community of Madrid\", \"Comunidad Valenciana\" and \"Valencian Community\",  \"País Vasco\" and \"Basque Country\"\n# Recode all Spanish names to the English alternative\ndataSet$state<-recode(dataSet$state, \"Andalucía\"=\"Andalusia\" ,\"Aragón\" = \"Aragon\",\"Castilla-La-Mancha\"=  \"Castile-La Mancha\",  \"Castilla y León\"=\"Castile-and-León\",  \"Cataluña\"=\"Catalonia\", \"Comunidad de Madrid\"=\"Community of Madrid\", \"Comunidad Valenciana\"=\"Valencian Community\",  \"País Vasco\"=\"Basque Country\")\n# Print the new levels of the `state` column\nlevels(dataSet$state)\n```\n\n```{r ex=\"factors2\", type=\"sct\"}\ntest_output_contains('dplyr', incorrect_msg = \"Make sure to load the dplyr package!\")\ntest_output_contains('mutate_if', incorrect_msg = \"Make sure to convert all character columns to factor!\")\ntest_output_contains('recode', incorrect_msg = \"Make sure to recode the factor 'state'!\")\nsuccess_msg(\"Great!\")\n```\n\n### 4.3 Re-organizing factors\n\n```{r ex=\"factors3\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"factors3\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\n\n# Print its levels\n\n# Relevel the corpus factor: its first value should be 'Twitter'\n\n```\n\n```{r ex=\"factors3\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\ndataSet$corpus <- as.factor(dataSet$corpus)\n# Print its levels\nlevels(dataSet$corpus )\n# Relevel the corpus factor: its first value should be 'Twitter'\ndataSet$corpus <- relevel(dataSet$corpus, ref=\"Twitter\")\n```\n\n```{r ex=\"factors3\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('levels', incorrect_msg = \"Make sure to print the levels of the factor!\")\ntest_output_contains('relevel', incorrect_msg = \"Make sure to reorder the levels of the factor!\")\nsuccess_msg(\"Great!\")\n```\n\n## 5. Frequencies: counting values\n### 5.1 Counting the `negation` variable \n```{r ex=\"counts_negation\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"counts_negation\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column negation to a factor\n\n# Compute a table for the negation variable, store it in the variable 'negationTab'\n\n# Convert 'negationTab' to a data.frame\n\n# Print 'negationTab'\n\n\n```\n\n```{r ex=\"counts_negation\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column negation to a factor\ndataSet$negation<-as.factor(dataSet$negation)\n# Compute a table for the negation variable, store it in the variable 'negationTab'\nnegationTab<-table(dataSet$negation)\n# Convert 'negationTab' to a data.frame\nnegationTab<-as.data.frame(negationTab)\n# Print 'negationTab'\nnegationTab\n```\n\n```{r ex=\"counts_negation\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to compute the table!\")\ntest_output_contains('as.data.frame', incorrect_msg = \"Make sure to convert the table to a data.frame!\")\nsuccess_msg(\"Great!\")\n```\n\n### 5.2 Counting the `province` variable \n```{r ex=\"counts_province\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"counts_province\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column province to a factor\n\n# Compute a table for the province variable, store it in the variable 'provinceTab'\n\n# Convert 'provinceTab' to a data.frame\n\n# Print 'provinceTab'\n\n\n```\n\n```{r ex=\"counts_province\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column province to a factor\ndataSet$province<-as.factor(dataSet$province)\n# Compute a table for the province variable, store it in the variable 'provinceTab'\nprovinceTab<-table(dataSet$province)\n# Convert 'provinceTab' to a data.frame\nprovinceTab<-as.data.frame(provinceTab)\n# Print 'provinceTab'\nprovinceTab\n```\n\n```{r ex=\"counts_province\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to compute the table!\")\ntest_output_contains('as.data.frame', incorrect_msg = \"Make sure to convert the table to a data.frame!\")\nsuccess_msg(\"Great!\")\n```\n\n### 5.3 Counting the `Typical.Action.Chain.Pos` variable \n```{r ex=\"counts_Typical.Action.Chain.Pos\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"counts_Typical.Action.Chain.Pos\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column Typical.Action.Chain.Pos to a factor\n\n# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'\n\n# Convert 'Typical.Action.Chain.PosTab' to a data.frame\n\n# Print 'Typical.Action.Chain.PosTab'\n\n\n```\n\n```{r ex=\"counts_Typical.Action.Chain.Pos\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column Typical.Action.Chain.Pos to a factor\ndataSet$Typical.Action.Chain.Pos<-as.factor(dataSet$Typical.Action.Chain.Pos)\n# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'\nTypical.Action.Chain.PosTab<-table(dataSet$Typical.Action.Chain.Pos)\n# Convert 'Typical.Action.Chain.PosTab' to a data.frame\nTypical.Action.Chain.PosTab<-as.data.frame(Typical.Action.Chain.PosTab)\n# Print 'Typical.Action.Chain.PosTab'\nTypical.Action.Chain.PosTab\n```\n\n```{r ex=\"counts_Typical.Action.Chain.Pos\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to compute the table!\")\ntest_output_contains('as.data.frame', incorrect_msg = \"Make sure to convert the table to a data.frame!\")\nsuccess_msg(\"Great!\")\n```\n\n\n## 6. Proportions\n### 6.1 Proportions for the `Typical.Action.Chain.Pos` variable \n```{r ex=\"proportionsTypical.Action.Chain.Pos\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"proportionsTypical.Action.Chain.Pos\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column Typical.Action.Chain.Pos to a factor\n\n# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'\n\n# Compute proportions for that table\n\n# Print 'Typical.Action.Chain.PosTab'\n\n\n```\n\n```{r ex=\"proportionsTypical.Action.Chain.Pos\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column Typical.Action.Chain.Pos to a factor\ndataSet$Typical.Action.Chain.Pos<-as.factor(dataSet$Typical.Action.Chain.Pos)\n# Compute a table for the Typical.Action.Chain.Pos variable, store it in the variable 'Typical.Action.Chain.PosTab'\nTypical.Action.Chain.PosTab<-table(dataSet$Typical.Action.Chain.Pos)\n# Convert 'Typical.Action.Chain.PosTab' to a data.frame\nTypical.Action.Chain.PosTab<-prop.table(Typical.Action.Chain.PosTab)\n# Print 'Typical.Action.Chain.PosTab'\nTypical.Action.Chain.PosTab\n```\n\n```{r ex=\"proportionsTypical.Action.Chain.Pos\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to compute the table!\")\ntest_output_contains('prop.table', incorrect_msg = \"Make sure to compute proportions for the table!\")\nsuccess_msg(\"Great!\")\n```\n\n### 6.2 Proportions for the `corpus` variable \n```{r ex=\"proportionscorpus\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"proportionscorpus\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\n\n# Compute a table for the corpus variable, store it in the variable 'corpusTab'\n\n# Convert the corpusTab object to a data.frame \n\n# Compute proportions based on the Freq column of that data.frame. Store the proportionsin a new column called 'prop'\n\n# Print corpusTab\n\n```\n\n```{r ex=\"proportionscorpus\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\ndataSet$corpus<-as.factor(dataSet$corpus)\n# Compute a table for the corpus variable, store it in the variable 'corpusTab'\ncorpusTab<-table(dataSet$corpus)\n# Convert 'corpusTab' to a data.frame\ncorpusTab<-as.data.frame(corpusTab)\n# Compute proportions based on the Freq column of that data.frame. Store the proportionsin a new column called 'prop'\ncorpusTab$prop<-corpusTab$Freq/sum(corpusTab$Freq, na.rm=TRUE)\n# Print corpusTab\ncorpusTab\n```\n\n```{r ex=\"proportionscorpus\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to compute the table!\")\ntest_output_contains('as.data.frame', incorrect_msg = \"Make sure to convert the table to a data.frame!\")\ntest_output_contains('sum', incorrect_msg = \"Make sure to compute the proportions!\")\nsuccess_msg(\"Great!\")\n```\n\n### 6.3 Proportions for the `broad.regions` variable \n```{r ex=\"proportionsbroad.regions\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"proportionsbroad.regions\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\n\n# Compute a table for the broad.regions variable, store it in the variable 'broad.regionsTab'\n\n# Compute proportions for the table. Overwrite the broad.regionsTab object\n\n# Multiply the proportions by 100\n\n# Round to 2 decimals\n\n# Print\n\n\n```\n\n```{r ex=\"proportionsbroad.regions\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\ndataSet$broad.regions<-as.factor(dataSet$broad.regions)\n# Compute a table for the broad.regions variable, store it in the variable 'broad.regionsTab'\nbroad.regionsTab<-table(dataSet$broad.regions)\n# Compute proportions for the table. Overwrite the broad.regionsTab object\nbroad.regionsTab<-prop.table(dataSet$broad.regions)\n# Multiply the proportions by 100\nbroad.regionsTab<-broad.regionsTab*100\n# Round to 2 decimals\nbroad.regionsTab<-round(broad.regionsTab, 2)\n# Print\nbroad.regionsTab\n```\n\n```{r ex=\"proportionsbroad.regions\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to compute the table!\")\ntest_output_contains('round', incorrect_msg = \"Make sure to round the proportions to 2 decimals!\")\ntest_output_contains('prop.table', incorrect_msg = \"Make sure to compute the proportions!\")\ntest_output_contains('100', incorrect_msg = \"Make sure to multiply the proportions by 100!\")\nsuccess_msg(\"Great!\")\n```\n\n## 7. Bar plots for Freq\n### 7.1 Exploring the counts of the `corpus` variable (1/2)\n- **ANALYZE**:\n      - Which corpus provided the most examples?\n\n```{r ex=\"freq1\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"freq1\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\n\n# Print a table of the number of times 'COSER' and 'Twitter' occur\n\n```\n\n```{r ex=\"freq1\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\ndataSet$corpus<-as.factor(dataSet$corpus)\n\n# Print a table of the number of times 'COSER' and 'Twitter' occ\ntable(dataSet$corpus)\n```\n\n```{r ex=\"freq1\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to print the table!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.1 Exploring the counts of the `corpus` variable (2/2)\n```{r ex=\"freq2\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"freq2\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\n\n# Load ggplot2\n\n# Draw a basic bar chart of the corpus factor\n\n```\n\n```{r ex=\"freq2\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\ndataSet$corpus<-as.factor(dataSet$corpus)\n# Load ggplot2\nlibrary(ggplot2)\n# Draw a basic bar chart of the corpus factor\nggplot(dataSet, aes(x=corpus)) + geom_bar()\n```\n\n```{r ex=\"freq2\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('geom_bar', incorrect_msg = \"Make sure to draw the bar chart!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.2 Exploring the counts of the `broad.regions` variable (1/2)\n- **ANALYZE**:\n    - Which broad.regions provided the most examples?\n\n```{r ex=\"broad.regions_1\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"broad.regions_1\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\n\n# Print a table of the number of times 'COSER' and 'Twitter' occur\n\n```\n\n```{r ex=\"broad.regions_1\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\ndataSet$broad.regions<-as.factor(dataSet$broad.regions)\n\n# Print a table of the number of occurrences that were provided by each region\ntable(dataSet$broad.regions)\n```\n\n```{r ex=\"broad.regions_1\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to print the table!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.2 Exploring the counts of the `broad.regions` variable (2/2)\n```{r ex=\"broad.regions\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"broad.regions\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\n\n# Load ggplot2\n\n# Draw a pretty bar chart of the broad.regions factor: each region has its own fill and color, there is no legend title, the Y axis title is \"Number of occurrences\", the X axis title is \"Large regions\", the plot title is \"Number of occurrences per region\"\n\n```\n\n```{r ex=\"broad.regions\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\ndataSet$broad.regions<-as.factor(dataSet$broad.regions)\n# Load ggplot2\nlibrary(ggplot2)\n# Draw a basic bar chart of the broad.regions factor\nggplot(dataSet, aes(x=broad.regions, fill=broad.regions, color=broad.regions)) + geom_bar() + theme(legend.title = element_blank()) + labs(x=\"Large regions\", y=\"Number of occurrences\", title=\"Number of occurrences per region\")\n```\n\n```{r ex=\"broad.regions\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('geom_bar', incorrect_msg = \"Make sure to draw the bar chart!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.3 Exploring the the counts of the `negation` variable \n- **ANALYZE**:\n    - Do tokens with and without negation occur with equal frequency?\n    \n```{r ex=\"negation\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"negation\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column negation to a factor\n\n# Print a table of the negation column\n\n# Load ggplot2\n\n# Draw a pretty bar chart of the negation factor: each value has its own fill and color, there is no legend title, the Y axis title is \"Number of occurrences\", the X axis title is \"Absence/presence of negation\", the plot title is \"Number of occurrences per Absence/presence of negation\"\n\n```\n\n```{r ex=\"negation\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column negation to a factor\ndataSet$negation<-as.factor(dataSet$negation)\n# Print a table of the negation column\ntable(dataSet$negation)\n# Load ggplot2\nlibrary(ggplot2)\n# Draw a basic bar chart of the negation factor\nggplot(dataSet, aes(x=negation, fill=negation, color=negation)) + geom_bar() + theme(legend.title = element_blank()) + labs(x=\"Large regions\", y=\"Number of occurrences\", title=\"Number of occurrences per region\")\n```\n\n```{r ex=\"negation\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to print a table of the column!\")\ntest_output_contains('geom_bar', incorrect_msg = \"Make sure to draw the bar chart!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.4 Exploring the proportions of the `corpus` variable (1/2)\n- **ANALYZE**:\n    - Which corpus provided the most examples?\n\n```{r ex=\"freq1_prop\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"freq1_prop\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\n\n# Print a table of the proportions of 'COSER' and 'Twitter' \n\n```\n\n```{r ex=\"freq1_prop\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\ndataSet$corpus<-as.factor(dataSet$corpus)\n\n# Print a table of the proportions of 'COSER' and 'Twitter' \nprop.table(table(dataSet$corpus))\n```\n\n```{r ex=\"freq1_prop\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to print the table!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.4 Exploring the proportions of the `corpus` variable (2/2)\n```{r ex=\"freq2\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"freq2\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\n\n# Load ggplot2\n\n# Draw a basic bar chart of the proportions of the corpus factor\n\n```\n\n```{r ex=\"freq2\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column corpus to a factor\ndataSet$corpus<-as.factor(dataSet$corpus)\n# Load ggplot2\nlibrary(ggplot2)\n# Draw a basic bar chart of the proportions of the corpus factor\nggplot(dataSet, aes(x=corpus)) + geom_bar(aes(y=..count../sum(..count..)))\n```\n\n```{r ex=\"freq2\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('geom_bar', incorrect_msg = \"Make sure to draw the bar chart!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.5 Exploring the proportions of the `broad.regions` variable (1/2)\n- **ANALYZE**:\n    - Which broad.regions provided the most examples?\n\n```{r ex=\"broad.regions_1\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"broad.regions_1\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\n\n# Print a table of the number of times 'COSER' and 'Twitter' occur\n\n```\n\n```{r ex=\"broad.regions_1\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\ndataSet$broad.regions<-as.factor(dataSet$broad.regions)\n\n# Print a table of the number of occurrences that were provided by each region\ntable(dataSet$broad.regions)\n```\n\n```{r ex=\"broad.regions_1\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to print the table!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.5 Exploring the proportions of the `broad.regions` variable (2/2)\n```{r ex=\"broad.regions_prop\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"broad.regions_prop\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\n\n# Load ggplot2\n\n# Draw a pretty bar chart of the proportions of the broad.regions factor: each region has its own fill and color, there is no legend title, the Y axis title is \"Number of occurrences\", the X axis title is \"Large regions\", the plot title is \"Number of occurrences per region\"\n\n```\n\n```{r ex=\"broad.regions_prop\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column broad.regions to a factor\ndataSet$broad.regions<-as.factor(dataSet$broad.regions)\n# Load ggplot2\nlibrary(ggplot2)\n# Draw a basic bar chart of the proportions of the broad.regions factor\nggplot(dataSet, aes(x=broad.regions, fill=broad.regions, color=broad.regions)) + geom_bar(aes(y=..count../sum(..count..))) + theme(legend.title = element_blank()) + labs(x=\"Large regions\", y=\"Number of occurrences\", title=\"Number of occurrences per region\")\n```\n\n```{r ex=\"broad.regions_prop\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('geom_bar', incorrect_msg = \"Make sure to draw the bar chart!\")\n\nsuccess_msg(\"Great!\")\n```\n\n### 7.6 Exploring the the proportions of the `negation` variable \n- **ANALYZE**:\n    - Do tokens with and without negation occur with equal frequency?\n\n```{r ex=\"negation_prop\", type=\"pre-exercise-code\"}\nlibrary(readr)\ndataSet <- read_csv(\"http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv\")\n```\n\n```{r ex=\"negation_prop\", type=\"sample-code\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column negation to a factor\n\n# Print a table of the negation column\n\n# Load ggplot2\n\n# Draw a pretty bar chart of the proportions of the negation factor: each value has its own fill and color, there is no legend title, the Y axis title is \"Number of occurrences\", the X axis title is \"Absence/presence of negation\", the plot title is \"Number of occurrences per Absence/presence of negation\"\n\n```\n\n```{r ex=\"negation_prop\", type=\"solution\"}\n# The data.frame dataSet is already in your workspace. \n\n# Convert the column negation to a factor\ndataSet$negation<-as.factor(dataSet$negation)\n# Print a table of the negation column\ntable(dataSet$negation)\n# Load ggplot2\nlibrary(ggplot2)\n# Draw a basic bar chart of the proportions of the negation factor\nggplot(dataSet, aes(x=negation, fill=negation, color=negation)) + geom_bar(aes(y=..count../sum(..count..))) + theme(legend.title = element_blank()) + labs(x=\"Large regions\", y=\"Number of occurrences\", title=\"Number of occurrences per region\")\n```\n\n```{r ex=\"negation_prop\", type=\"sct\"}\ntest_output_contains('as.factor', incorrect_msg = \"Make sure to convert the column to a factor!\")\ntest_output_contains('table', incorrect_msg = \"Make sure to print a table of the column!\")\ntest_output_contains('geom_bar', incorrect_msg = \"Make sure to draw the bar chart!\")\n\nsuccess_msg(\"Great!\")\n```\n\n",
    "created" : 1518437305938.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "508|41|547|0|\n",
    "hash" : "2803418052",
    "id" : "85A3F984",
    "lastKnownWriteTime" : 1518568956,
    "last_content_update" : 1518568956070,
    "path" : "~/Desktop/statistics_for_linguistics/labs/class3.Rmd",
    "project_path" : "class3.Rmd",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}